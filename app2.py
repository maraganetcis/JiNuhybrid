import streamlit as st
import google.generativeai as genai
import requests
import sqlite3
import hashlib
import time
import logging
from datetime import datetime
from typing import Dict, List, Optional
import json
import os

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# âœ… í˜ì´ì§€ ì„¤ì • - ë” ì˜ˆìœ ë””ìì¸
st.set_page_config(
    page_title="JiNu hybrid AI",
    page_icon="ğŸ’ ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/your-repo',
        'Report a bug': "https://github.com/your-repo/issues",
        'About': "# ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ AI/n ìµœì ì˜ AI ëª¨ë¸"
    }
)

# âœ… CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 3.5rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: 800;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #6c757d;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: 300;
    }
    .free-badge {
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 15px;
        font-size: 0.8rem;
        font-weight: bold;
        margin-left: 0.5rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #667eea;
        margin: 0.5rem 0;
    }
    .model-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .intent-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 600;
        margin: 0.1rem;
    }
    .complexity-high { background: #ff6b6b; color: white; }
    .complexity-medium { background: #ffd93d; color: black; }
    .complexity-low { background: #6bcf7f; color: white; }
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 0.5rem 0;
    }
    .assistant-message {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 15px;
        border-left: 4px solid #667eea;
        margin: 0.5rem 0;
    }
    .stats-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .rate-limit-warning {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        color: #856404;
    }
</style>
""", unsafe_allow_html=True)

class FreePlanAISystem:
    def __init__(self):
        self.setup_api_keys()
        self.setup_database()
        self.initialize_session_state()
        self.setup_rate_limiting()
        logger.info("í•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_api_keys(self):
        """API í‚¤ ì„¤ì • - ë¬´ë£Œ í”Œëœ ìµœì í™”"""
        try:
            # Google Gemini (ë¬´ë£Œ í”Œëœ)
            if 'GEMINI_API_KEY' in st.secrets:
                genai.configure(api_key=st.secrets['GEMINI_API_KEY'])
                self.gemini_available = True
                logger.info("Gemini API")
            else:
                self.gemini_available =I False
                logger.warning("Gemini API í‚¤ ì—†ìŒ")
            
            # OpenRouter (ë¬´ë£Œ í¬ë ˆë”§ ìˆëŠ” ê²½ìš°)
            self.openrouter_key = st.secrets.get('OPENROUTER_API_KEY', '')
            self.openrouter_available = bool(self.openrouter_key)
            if self.openrouter_available:
                logger.info("OpenRouter ì„¤ì • ì™„ë£Œ")
            
            # DeepSeek (ë¬´ë£Œ)
            self.deepseek_key = st.secrets.get('DEEPSEEK_API_KEY', '')
            self.deepseek_available = bool(self.deepseek_key)
            if self.deepseek_available:
                logger.info("DeepSeek API ì„¤ì • ì™„ë£Œ")
                
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
            self.available_models = []
            if self.gemini_available:
                self.available_models.append('gemini')
            if self.openrouter_available:
                self.available_models.append('claude')
            if self.deepseek_available:
                self.available_models.append('deepseek')
                
            logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {self.available_models}")
                
        except Exception as e:
            logger.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
            st.error("API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def setup_rate_limiting(self):
        """ë¬´ë£Œ í”Œëœì„ ìœ„í•œ ìš”ì²­ ì œí•œ ì„¤ì •"""
        self.rate_limits = {
            'gemini': {'count': 0, 'last_reset': time.time(), 'max_per_minute': 15},
            'claude': {'count': 0, 'last_reset': time.time(), 'max_per_minute': 10},
            'deepseek': {'count': 0, 'last_reset': time.time(), 'max_per_minute': 20}
        }
    
    def check_rate_limit(self, model: str) -> bool:
        """ìš”ì²­ ì œí•œ í™•ì¸"""
        current_time = time.time()
        limit_info = self.rate_limits[model]
        
        # 1ë¶„ ì´ìƒ ì§€ë‚¬ìœ¼ë©´ ë¦¬ì…‹
        if current_time - limit_info['last_reset'] > 60:
            limit_info['count'] = 0
            limit_info['last_reset'] = current_time
        
        # ì œí•œ ì²´í¬
        if limit_info['count'] >= limit_info['max_per_minute']:
            return False
        
        limit_info['count'] += 1
        return True
    
    def setup_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
        try:
            self.conn = sqlite3.connect('ai_system.db', check_same_thread=False)
            cursor = self.conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    user_message TEXT,
                    bot_response TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    model_used TEXT,
                    intent_detected TEXT,
                    processing_time REAL,
                    tokens_used INTEGER,
                    rate_limited BOOLEAN DEFAULT FALSE
                )
            ''')
            
            self.conn.commit()
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        if 'user_id' not in st.session_state:
            st.session_state.user_id = hashlib.md5(
                str(datetime.now().timestamp()).encode()
            ).hexdigest()
        
        if 'conversation_count' not in st.session_state:
            st.session_state.conversation_count = 0
        
        if 'model_usage' not in st.session_state:
            st.session_state.model_usage = {}
        
        if 'rate_limit_hits' not in st.session_state:
            st.session_state.rate_limit_hits = 0

    def advanced_intent_analysis(self, user_input: str) -> Dict:
        """ê³ ê¸‰ ì˜ë„ ë¶„ì„ ì‹œìŠ¤í…œ - ë¬´ë£Œ ëª¨ë¸ì— ìµœì í™”"""
        intent_keywords = {
            'complex_reasoning': [
                'ë…¼ë¦¬', 'ì¶”ë¡ ', 'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'íŒë‹¨', 'ê²°ë¡ ', 'ê°€ì •',
                'ì „ì œ', 'ë…¼ì¦', 'íƒ€ë‹¹ì„±', 'ë¹„íŒì ', 'ì‚¬ê³ ', 'ì´ìœ ', 'ê·¼ê±°',
                'ë³µì¡í•œ', 'ë‚œì´ë„', 'ì‹¬ì¸µ', 'ë‹¤ë‹¨ê³„', 'ì¢…í•©', 'í†µí•©', 'ì² í•™'
            ],
            'technical': [
                'ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°', 'ì•Œê³ ë¦¬ì¦˜', 'ê°œë°œ', 'ì„¤ê³„', 'íŒŒì´ì¬', 'ìë°”', 
                'í•¨ìˆ˜', 'í´ë˜ìŠ¤', 'ë””ë²„ê¹…', 'API', 'JSON', 'ë¦¬íŒ©í† ë§'
            ],
            'creative': [
                'ì‘ì„±', 'ìƒì„±', 'ë§Œë“¤', 'ê¸€ì“°ê¸°', 'ì‹œ', 'ì´ì•¼ê¸°', 'ì°½ì˜', 'ì†Œì„¤',
                'ì•„ì´ë””ì–´', 'ê¸°íš', 'ì½˜í…ì¸ '
            ],
            'mathematical': [
                'ê³„ì‚°', 'ìˆ˜í•™', 'ê³µì‹', 'ë°©ì •ì‹', 'í†µê³„', 'í™•ë¥ ', 'ë¯¸ë¶„', 'ì ë¶„'
            ],
            'research': [
                'ì—°êµ¬', 'ë…¼ë¬¸', 'ì°¸ê³ ë¬¸í—Œ', 'í•™ìˆ ', 'ì´ë¡ ', 'ì‹¤í—˜', 'ë°ì´í„°', 'ì¡°ì‚¬'
            ],
            'factual': [
                'ë­ì•¼', 'ë¬´ì—‡', 'ì•Œë ¤ì¤˜', 'ì •ë³´', 'ì‚¬ì‹¤', 'ì •ì˜', 'ì„¤ëª…'
            ],
            'casual': [
                'ì•ˆë…•', 'í•˜ì´', 'ì˜ì§€ë‚´', 'ê³ ë§ˆì›Œ', 'ë°˜ê°€ì›Œ'
            ]
        }
        
        # ì˜ë„ ì ìˆ˜ ê³„ì‚°
        intent_scores = {}
        user_lower = user_input.lower()
        
        for intent, keywords in intent_keywords.items():
            score = sum(10 for keyword in keywords if keyword in user_lower)
            if score > 0:
                intent_scores[intent] = score
        
        # ë³µì¡ë„ ë¶„ì„
        word_count = len(user_input.split())
        if word_count > 25:
            complexity = 'very_high'
        elif word_count > 15:
            complexity = 'high'
        elif word_count > 7:
            complexity = 'medium'
        else:
            complexity = 'low'
        
        # ì£¼ìš” ì˜ë„ ì„ íƒ
        primary_intent = 'general'
        if intent_scores:
            if 'complex_reasoning' in intent_scores:
                primary_intent = 'complex_reasoning'
            else:
                primary_intent = max(intent_scores.items(), key=lambda x: x[1])[0]
        
        return {
            'primary_intent': primary_intent,
            'all_intents': list(intent_scores.keys()),
            'intent_scores': intent_scores,
            'complexity': complexity,
            'word_count': word_count,
            'is_complex': complexity in ['high', 'very_high']
        }

    def select_optimal_model(self, intent_analysis: Dict) -> Dict:
        """ë¬´ë£Œ í”Œëœì— ìµœì í™”ëœ ëª¨ë¸ ì„ íƒ"""
        
        # ë¬´ë£Œ í”Œëœ ëª¨ë¸ ë§¤í•‘ (Gemini Advanced ì œê±°)
        intent_model_mapping = {
            'complex_reasoning': {
                'primary': 'claude',
                'backup': 'deepseek',
                'fallback': 'gemini',
                'reason': 'ğŸ§  ë³µì¡í•œ ë…¼ë¦¬/ì¶”ë¡ ì—ëŠ” Claude 3.5 Sonnetì´ ê°€ì¥ ìš°ìˆ˜',
                'specialization': 'ë…¼ë¦¬ì  ì¶”ë¡ , ì²´ê³„ì  ë¶„ì„',
                'icon': 'ğŸ§ '
            },
            'technical': {
                'primary': 'deepseek',
                'backup': 'gemini', 
                'fallback': 'claude',
                'reason': 'ğŸ’» ì½”ë“œ ë° ê¸°ìˆ ì  ë¬¸ì œ í•´ê²°ì—ëŠ” DeepSeek V3ê°€ ìµœì í™”',
                'specialization': 'í”„ë¡œê·¸ë˜ë°, ì•Œê³ ë¦¬ì¦˜, ê°œë°œ',
                'icon': 'ğŸ’»'
            },
            'mathematical': {
                'primary': 'deepseek',
                'backup': 'gemini',
                'fallback': 'claude',
                'reason': 'ğŸ§® ìˆ˜í•™ì /ë…¼ë¦¬ì  ì—°ì‚°ì—ëŠ” DeepSeek V3ê°€ ê°•ë ¥',
                'specialization': 'ìˆ˜í•™, ê³„ì‚°, ê³µì‹',
                'icon': 'ğŸ§®'
            },
            'research': {
                'primary': 'gemini',
                'backup': 'claude',
                'fallback': 'deepseek',
                'reason': 'ğŸ“š ë°©ëŒ€í•œ í…ìŠ¤íŠ¸/ì—°êµ¬ ë¶„ì„ì—ëŠ” Geminiê°€ ìœ ë¦¬',
                'specialization': 'ì—°êµ¬, ë…¼ë¬¸, í•™ìˆ  ë¶„ì„',
                'icon': 'ğŸ“š'
            },
            'creative': {
                'primary': 'claude',
                'backup': 'gemini',
                'fallback': 'deepseek',
                'reason': 'ğŸ¨ ìì—°ìŠ¤ëŸ½ê³  ì°½ì˜ì ì¸ ì‘ë¬¸ì€ Claudeê°€ ë›°ì–´ë‚¨',
                'specialization': 'ì°½ì˜ì„±, ì•„ì´ë””ì–´, ê¸€ì“°ê¸°',
                'icon': 'ğŸ¨'
            },
            'general': {
                'primary': 'gemini',
                'backup': 'deepseek',
                'fallback': 'claude',
                'reason': 'âš¡ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì—ëŠ” ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ Gemini Flash ì‚¬ìš©',
                'specialization': 'ì¼ë°˜ ëŒ€í™”, ê¸°ë³¸ ì§ˆë¬¸',
                'icon': 'âš¡'
            }
        }
        
        primary_intent = intent_analysis['primary_intent']
        model_choice = intent_model_mapping.get(primary_intent, intent_model_mapping['general'])
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì— ë”°ë¼ ì„ íƒ ì¡°ì •
        selected_model = None
        
        # 1ìˆœìœ„ ëª¨ë¸ ì²´í¬
        if model_choice['primary'] in self.available_models:
            if self.check_rate_limit(model_choice['primary']):
                selected_model = model_choice['primary']
        
        # 2ìˆœìœ„ ë°±ì—… ëª¨ë¸ ì²´í¬
        if not selected_model and model_choice['backup'] in self.available_models:
            if self.check_rate_limit(model_choice['backup']):
                selected_model = model_choice['backup']
                model_choice['reason'] += " (1ìˆœìœ„ ëª¨ë¸ ì œí•œìœ¼ë¡œ ë°±ì—… ì‚¬ìš©)"
        
        # 3ìˆœìœ„ í´ë°± ëª¨ë¸ ì²´í¬
        if not selected_model and model_choice['fallback'] in self.available_models:
            if self.check_rate_limit(model_choice['fallback']):
                selected_model = model_choice['fallback']
                model_choice['reason'] += " (ë°±ì—… ëª¨ë¸ ì œí•œìœ¼ë¡œ í´ë°± ì‚¬ìš©)"
        
        # ëª¨ë“  ëª¨ë¸ì´ ì œí•œëœ ê²½ìš°
        if not selected_model:
            # ì œí•œì´ ê°€ì¥ ì ì€ ëª¨ë¸ ì°¾ê¸°
            for model in self.available_models:
                if self.check_rate_limit(model):
                    selected_model = model
                    model_choice['reason'] = f"âš ï¸ ëª¨ë“  ìµœì  ëª¨ë¸ ì œí•œìœ¼ë¡œ {model} ê°•ì œ ì‚¬ìš©"
                    break
        
        model_choice['primary'] = selected_model
        return model_choice

    def call_gemini_api(self, prompt: str, intent: str) -> Dict:
        """Gemini API í˜¸ì¶œ - ë¬´ë£Œ í”Œëœìš©"""
        if not self.gemini_available:
            return {'success': False, 'error': 'Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        try:
            start_time = time.time()
            
            # ë¬´ë£Œ í”Œëœì—ì„œëŠ” í•­ìƒ gemini-2.5-flash ì‚¬ìš©
            model_name = 'gemini-2.5-flash'
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            
            processing_time = time.time() - start_time
            
            # ëª¨ë¸ ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
            st.session_state.model_usage['gemini'] = st.session_state.model_usage.get('gemini', 0) + 1
            
            return {
                'success': True,
                'content': response.text,
                'model': f"Google {model_name}",
                'processing_time': processing_time,
                'tokens': len(prompt + response.text) // 4
            }
            
        except Exception as e:
            logger.error(f"Gemini API ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': f'Gemini API ì˜¤ë¥˜: {str(e)}'}

    def call_openrouter_api(self, prompt: str, intent: str) -> Dict:
        """OpenRouter API í˜¸ì¶œ - Claude (ë¬´ë£Œ í¬ë ˆë”§)"""
        if not self.openrouter_available:
            return {'success': False, 'error': 'OpenRouter APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        try:
            start_time = time.time()
            
            data = {
                "model": "anthropic/claude-3.5-sonnet",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 4000,
                "temperature": 0.3
            }
            
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.openrouter_key}",
                    "Content-Type": "application/json"
                },
                json=data,
                timeout=60
            )
            
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens = result.get('usage', {}).get('total_tokens', 0)
                
                # ëª¨ë¸ ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
                st.session_state.model_usage['claude'] = st.session_state.model_usage.get('claude', 0) + 1
                
                return {
                    'success': True,
                    'content': content,
                    'model': "Claude 3.5 Sonnet",
                    'processing_time': processing_time,
                    'tokens': tokens
                }
            else:
                return {
                    'success': False, 
                    'error': f'OpenRouter API ì˜¤ë¥˜: {response.status_code}'
                }
                
        except Exception as e:
            logger.error(f"OpenRouter ì—°ê²° ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': f'OpenRouter ì—°ê²° ì˜¤ë¥˜: {str(e)}'}

    def call_deepseek_api(self, prompt: str, intent: str) -> Dict:
        """DeepSeek API í˜¸ì¶œ - ë¬´ë£Œ"""
        if not self.deepseek_available:
            return {'success': False, 'error': 'DeepSeek APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        try:
            start_time = time.time()
            
            data = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 4000,
                "temperature": 0.1
            }
            
            response = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {self.deepseek_key}"},
                json=data,
                timeout=60
            )
            
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens = result.get('usage', {}).get('total_tokens', 0)
                
                # ëª¨ë¸ ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
                st.session_state.model_usage['deepseek'] = st.session_state.model_usage.get('deepseek', 0) + 1
                
                return {
                    'success': True,
                    'content': content,
                    'model': "DeepSeek V3",
                    'processing_time': processing_time,
                    'tokens': tokens
                }
            else:
                return {
                    'success': False,
                    'error': f'DeepSeek API ì˜¤ë¥˜: {response.status_code}'
                }
                
        except Exception as e:
            logger.error(f"DeepSeek API ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': f'DeepSeek API ì˜¤ë¥˜: {str(e)}'}

    def intelligent_model_orchestration(self, user_input: str) -> Dict:
        """ë¬´ë£Œ í”Œëœìš© ì§€ëŠ¥í˜• ëª¨ë¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""
        start_time = time.time()
        
        # 1. ê³ ê¸‰ ì˜ë„ ë¶„ì„
        intent_analysis = self.advanced_intent_analysis(user_input)
        
        # 2. ìµœì  ëª¨ë¸ ì„ íƒ (ë¬´ë£Œ í”Œëœ ê³ ë ¤)
        model_choice = self.select_optimal_model(intent_analysis)
        
        # 3. ì„ íƒëœ ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
        selected_model = model_choice['primary']
        responses = {}
        
        if selected_model == 'claude':
            response = self.call_openrouter_api(user_input, intent_analysis['primary_intent'])
            if response['success']:
                responses['claude'] = response
        elif selected_model == 'deepseek':
            response = self.call_deepseek_api(user_input, intent_analysis['primary_intent'])
            if response['success']:
                responses['deepseek'] = response
        elif selected_model == 'gemini':
            response = self.call_gemini_api(user_input, intent_analysis['primary_intent'])
            if response['success']:
                responses['gemini'] = response
        
        # 4. ê¸°ë³¸ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ë°±ì—… ëª¨ë¸ ì‹œë„
        if not responses and model_choice.get('backup'):
            backup_model = model_choice['backup']
            if backup_model == 'claude' and self.openrouter_available and self.check_rate_limit('claude'):
                response = self.call_openrouter_api(user_input, intent_analysis['primary_intent'])
                if response['success']:
                    responses['claude'] = response
                    selected_model = 'claude'
                    model_choice['reason'] += " (ì£¼ ëª¨ë¸ ì‹¤íŒ¨ë¡œ ë°±ì—… ì‚¬ìš©)"
            elif backup_model == 'gemini' and self.gemini_available and self.check_rate_limit('gemini'):
                response = self.call_gemini_api(user_input, intent_analysis['primary_intent'])
                if response['success']:
                    responses['gemini'] = response
                    selected_model = 'gemini'
                    model_choice['reason'] += " (ì£¼ ëª¨ë¸ ì‹¤íŒ¨ë¡œ ë°±ì—… ì‚¬ìš©)"
            elif backup_model == 'deepseek' and self.deepseek_available and self.check_rate_limit('deepseek'):
                response = self.call_deepseek_api(user_input, intent_analysis['primary_intent'])
                if response['success']:
                    responses['deepseek'] = response
                    selected_model = 'deepseek'
                    model_choice['reason'] += " (ì£¼ ëª¨ë¸ ì‹¤íŒ¨ë¡œ ë°±ì—… ì‚¬ìš©)"
        
        # 5. ìµœì¢… ì‘ë‹µ ì„ íƒ
        final_response = self.get_final_response(responses)
        total_processing_time = time.time() - start_time
        
        result = {
            'final_response': final_response,
            'selected_model': selected_model,
            'model_reason': model_choice['reason'],
            'model_specialization': model_choice.get('specialization', 'ì¼ë°˜'),
            'model_icon': model_choice.get('icon', 'ğŸ¤–'),
            'intent_analysis': intent_analysis,
            'processing_time': total_processing_time,
            'success': bool(responses),
            'rate_limited': not bool(responses) and selected_model is not None
        }
        
        # ì„±ê³µí•œ ì‘ë‹µì´ ìˆìœ¼ë©´ ìƒì„¸ ì •ë³´ ì¶”ê°€
        if responses:
            first_response = next(iter(responses.values()))
            result.update({
                'content': first_response['content'],
                'model_name': first_response['model'],
                'response_time': first_response['processing_time'],
                'tokens_used': first_response['tokens']
            })
        
        return result

    def get_final_response(self, responses: Dict) -> str:
        """ìµœì¢… ì‘ë‹µ ì„ íƒ"""
        if responses:
            for response in responses.values():
                if response['success']:
                    return response['content']
        
        return "âš ï¸ í˜„ì¬ ëª¨ë“  AI ëª¨ë¸ì˜ ìš”ì²­ ì œí•œì— ë„ë‹¬í–ˆê±°ë‚˜ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    def save_conversation(self, user_input: str, result: Dict):
        """ëŒ€í™” ì €ì¥"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT INTO conversations 
                (session_id, user_message, bot_response, model_used, intent_detected, processing_time, tokens_used, rate_limited)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                st.session_state.user_id,
                user_input,
                result.get('content', ''),
                result.get('model_name', ''),
                result['intent_analysis']['primary_intent'],
                result['processing_time'],
                result.get('tokens_used', 0),
                result.get('rate_limited', False)
            ))
            
            self.conn.commit()
            st.session_state.conversation_count += 1
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ì €ì¥ ì˜¤ë¥˜: {e}")

    def display_beautiful_sidebar(self):
        """ë¬´ë£Œ í”Œëœ ìµœì í™” ì‚¬ì´ë“œë°”"""
        with st.sidebar:
            # í—¤ë”
            st.markdown('<div class="main-header">ğŸ’ í•˜ì´ë¸Œë¦¬ë“œ AI</div>', unsafe_allow_html=True)
            
            # ë¬´ë£Œ í”Œëœ ë°°ì§€
            st.markdown(
                '<div style="text-align: center; margin-bottom: 1rem;">'
                '<span class="free-badge">HYBRID</span>'
                '</div>', 
                unsafe_allow_html=True
            )
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ì¹´ë“œ
            st.markdown("### ğŸ”§ ëª¨ë¸ ìƒíƒœ")
            col1, col2, col3 = st.columns(3)
            with col1:
                status = "âœ…" if self.gemini_available else "âŒ"
                st.metric("Gemini Flash", status, help="Google Gemini")
            with col2:
                status = "âœ…" if self.openrouter_available else "âŒ"
                st.metric("Claude", status, help="OpenRouter ")
            with col3:
                status = "âœ…" if self.deepseek_available else "âŒ"
                st.metric("DeepSeek", status, help="DeepSeek API")
            
            st.markdown("---")
            
            # ìš”ì²­ ì œí•œ ì •ë³´
            st.markdown("### ğŸ“Š í˜„ì¬ ì‚¬ìš©ëŸ‰")
            
            for model, limits in self.rate_limits.items():
                if model in self.available_models:
                    remaining = max(0, limits['max_per_minute'] - limits['count'])
                    st.progress(
                        limits['count'] / limits['max_per_minute'],
                        text=f"{model}: {limits['count']}/{limits['max_per_minute']} íšŒ"
                    )
            
            st.markdown("---")
            
            # í†µê³„ ì¹´ë“œ
            st.markdown("### ğŸ“ˆ ì‚¬ìš© í†µê³„")
            st.markdown(f"""
            <div class="stats-card">
                <div style="font-size: 2rem; font-weight: bold; color: #667eea; text-align: center;">
                    {st.session_state.conversation_count}
                </div>
                <div style="text-align: center; color: #6c757d;">ì´ ëŒ€í™” ìˆ˜</div>
            </div>
            """, unsafe_allow_html=True)
            
            # ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰
            if st.session_state.model_usage:
                st.markdown("#### ğŸ¯ ëª¨ë¸ ì‚¬ìš© ë¹„ìœ¨")
                total_usage = sum(st.session_state.model_usage.values())
                for model, count in st.session_state.model_usage.items():
                    percentage = (count / total_usage * 100) if total_usage > 0 else 0
                    st.write(f"{model}: {count}íšŒ ({percentage:.1f}%)")
            
            st.markdown("---")
            
            # ë¬´ë£Œ ëª¨ë¸ íŠ¹ê¸° ì•ˆë‚´
            st.markdown("### ğŸ† ëª¨ë¸ íŠ¹ê¸°")
            
           # free_model_specs ë¦¬ìŠ¤íŠ¸ ìˆ˜ì • (type í‚¤ ì œê±°)
free_model_specs = [
    {"icon": "ğŸ§ ", "name": "Claude 3.5", "desc": "ë…¼ë¦¬ì  ì¶”ë¡ , ì°½ì˜ì  ì‘ë¬¸"},
    {"icon": "âš¡", "name": "Gemini Flash", "desc": "ë¹ ë¥¸ ì‘ë‹µ, ì¼ë°˜ ì§ˆë¬¸"}, 
    {"icon": "ğŸ’»", "name": "DeepSeek V3", "desc": "ì½”ë”©, ìˆ˜í•™, ê¸°ìˆ  ì§ˆë¬¸"}
]
            
            for spec in free_model_specs:
                st.markdown(f"""
                <div class="model-card">
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <div style="font-size: 1.2rem;">
                            {spec['icon']} <strong>{spec['name']}</strong>
                        </div>
                        <span class="free-badge" style="font-size: 0.6rem; padding: 0.2rem 0.5rem;">{spec['type']}</span>
                    </div>
                    <div style="color: #6c757d; font-size: 0.9rem; margin-top: 0.5rem;">
                        {spec['desc']}
                    </div>
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown("---")
            
            # ë¬´ë£Œ í”Œëœ ì‚¬ìš© íŒ
            st.markdown("### ğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ AI íŒ")
            tips = [
                "ğŸ”„ **ëª¨ë¸ ìˆœí™˜**: ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ëª¨ë¸ì„ ì „í™˜í•´ìš”",
                "â±ï¸ **ìš”ì²­ ë¶„ì‚°**: ë¶„ë‹¹ ìš”ì²­ ì œí•œì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ í•´ìš”", 
                "ğŸ¯ **ì˜ë„ ëª…í™•íˆ**: ì§ˆë¬¸ì„ ëª…í™•íˆ í•˜ë©´ ë” ì¢‹ì€ ì‘ë‹µì„ ë°›ì•„ìš”",
                "âš¡ **ê°€ë²¼ìš´ ì§ˆë¬¸**: Gemini Flashê°€ ê°€ì¥ ë¹ ë¥´ê³  ê²½ì œì ì´ì—ìš”"
            ]
            
            for tip in tips:
                st.markdown(f"<div style='margin: 0.5rem 0; font-size: 0.9rem;'>{tip}</div>", unsafe_allow_html=True)
            
            # ëŒ€í™” ì§€ìš°ê¸° ë²„íŠ¼
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°", use_container_width=True, type="secondary"):
                st.session_state.messages = []
                st.session_state.conversation_count = 0
                st.session_state.model_usage = {}
                st.rerun()

    def display_beautiful_chat(self):
        """ë¬´ë£Œ í”Œëœ ìµœì í™” ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
        # í—¤ë”
        st.markdown('<div class="main-header">ğŸ’  í•˜ì´ë¸Œë¦¬ë“œ AI</div>', unsafe_allow_html=True)
        st.markdown(
            '<div class="sub-header">'
            'í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤<br>'
            '<small>ìš”ì²­ ì œí•œì„ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ìë™ ì„ íƒ</small>'
            '</div>', 
            unsafe_allow_html=True
        )
        
        # ìš”ì²­ ì œí•œ ê²½ê³  í‘œì‹œ
        total_requests = sum(limit['count'] for limit in self.rate_limits.values())
        if total_requests > 50:
            st.markdown("""
            <div class="rate-limit-warning">
                âš ï¸ <strong>ìš”ì²­ ì œí•œ ì ‘ê·¼ ì¤‘</strong><br>
                í˜„ì¬ ë§ì€ ìš”ì²­ì„ ë³´ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ë¬´ë£Œ í”Œëœ ì œí•œì„ ì´ˆê³¼í•˜ë©´ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            </div>
            """, unsafe_allow_html=True)
        
        # ì±„íŒ… ì»¨í…Œì´ë„ˆ
        chat_container = st.container()
        
        with chat_container:
            # ëŒ€í™” ê¸°ë¡
            for message in st.session_state.messages:
                if message["role"] == "user":
                    st.markdown(f"""
                    <div style="display: flex; justify-content: flex-end; margin: 1rem 0;">
                        <div class="user-message" style="max-width: 70%;">
                            <div style="font-weight: 600; margin-bottom: 0.5rem;">ğŸ‘¤ You</div>
                            {message["content"]}
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    # AI ì‘ë‹µ ë©”íƒ€ì •ë³´
                    metadata_html = ""
                    if "metadata" in message:
                        meta = message['metadata']
                        complexity_class = f"complexity-{meta['intent_analysis']['complexity']}"
                        
                        # ë¬´ë£Œ ë°°ì§€ ì¶”ê°€
                        free_badge = ""
                        if 'Gemini' in meta['model_name']:
                            free_badge = '<span class="free-badge" style="font-size: 0.6rem; margin-left: 0.5rem;">FREE</span>'
                        elif 'DeepSeek' in meta['model_name']:
                            free_badge = '<span class="free-badge" style="font-size: 0.6rem; margin-left: 0.5rem;">FREE</span>'
                        
                        metadata_html = f"""
                        <div style="margin-top: 1rem; padding: 1rem; background: white; border-radius: 10px; border: 1px solid #e0e0e0;">
                            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 1rem; margin-bottom: 1rem;">
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">ì„ íƒ ëª¨ë¸</div>
                                    <div style="font-weight: 600; color: #667eea; display: flex; align-items: center;">
                                        {meta['model_name']} {free_badge}
                                    </div>
                                </div>
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">ê°ì§€ ì˜ë„</div>
                                    <div style="font-weight: 600;">{meta['intent_analysis']['primary_intent']}</div>
                                </div>
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">ë³µì¡ë„</div>
                                    <span class="intent-badge {complexity_class}">
                                        {meta['intent_analysis']['complexity']}
                                    </span>
                                </div>
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">ì²˜ë¦¬ ì‹œê°„</div>
                                    <div style="font-weight: 600;">{meta['response_time']:.2f}s</div>
                                </div>
                            </div>
                            <div style="font-size: 0.9rem; color: #495057;">
                                <strong>ì„ íƒ ì´ìœ :</strong> {meta['model_reason']}
                            </div>
                        </div>
                        """
                    
                    st.markdown(f"""
                    <div style="display: flex; justify-content: flex-start; margin: 1rem 0;">
                        <div class="assistant-message" style="max-width: 70%;">
                            <div style="font-weight: 600; margin-bottom: 0.5rem;">ğŸ¤– Assistant</div>
                            {message["content"]}
                            {metadata_html}
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
        
        # ì…ë ¥ì°½
        st.markdown("---")
        prompt = st.chat_input(
            "í•˜ì´ë¸Œë¦¬ë“œ AIì—ê²Œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
            key="chat_input"
        )
        
        if prompt:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # AI ì‘ë‹µ ìƒì„±
            with st.spinner("ğŸ¤” í•˜ì´ë¸Œë¦¬ë“œ AIê°€ ë‹µë³€ ìƒì„± ì¤‘..."):
                result = self.intelligent_model_orchestration(prompt)
            
            if result['success']:
                # ì„±ê³µí•œ ì‘ë‹µ í‘œì‹œ
                complexity_class = f"complexity-{result['intent_analysis']['complexity']}"
                
                # ë¬´ë£Œ ë°°ì§€
                free_badge = ""
                if 'Gemini' in result['model_name'] or 'DeepSeek' in result['model_name']:
                    free_badge = '<span class="free-badge" style="font-size: 0.6rem; margin-left: 0.5rem;">FREE</span>'
                elif 'Claude' in result['model_name']:
                    free_badge = '<span class="free-badge" style="font-size: 0.6rem; margin-left: 0.5rem;">FREE CREDIT</span>'
                
                response_html = f"""
                <div style="display: flex; justify-content: flex-start; margin: 1rem 0;">
                    <div class="assistant-message" style="max-width: 70%;">
                        <div style="font-weight: 600; margin-bottom: 0.5rem;">ğŸ¤– Assistant</div>
                        {result['content']}
                        <div style="margin-top: 1rem; padding: 1rem; background: white; border-radius: 10px; border: 1px solid #e0e0e0;">
                            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 1rem; margin-bottom: 1rem;">
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">ì„ íƒ ëª¨ë¸</div>
                                    <div style="font-weight: 600; color: #667eea; display: flex; align-items: center;">
                                        {result['model_name']} {free_badge}
                                    </div>
                                </div>
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">ê°ì§€ ì˜ë„</div>
                                    <div style="font-weight: 600;">{result['intent_analysis']['primary_intent']}</div>
                                </div>
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">ë³µì¡ë„</div>
                                    <span class="intent-badge {complexity_class}">
                                        {result['intent_analysis']['complexity']}
                                    </span>
                                </div>
                                <div>
                                    <div style="font-size: 0.8rem; color: #6c757d;">í† í°</div>
                                    <div style="font-weight: 600;">{result['tokens_used']}</div>
                                </div>
                            </div>
                            <div style="font-size: 0.9rem; color: #495057;">
                                <strong>ì„ íƒ ì´ìœ :</strong> {result['model_reason']}
                            </div>
                            <div style="font-size: 0.8rem; color: #6c757d; margin-top: 0.5rem;">
                                ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ
                            </div>
                        </div>
                    </div>
                </div>
                """
                
                st.markdown(response_html, unsafe_allow_html=True)
                
                # ì„¸ì…˜ì— ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": result['content'],
                    "metadata": {
                        'model_name': result['model_name'],
                        'model_reason': result['model_reason'],
                        'intent_analysis': result['intent_analysis'],
                        'response_time': result.get('response_time', 0),
                        'tokens_used': result.get('tokens_used', 0)
                    }
                })
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                self.save_conversation(prompt, result)
                
            else:
                # ì‹¤íŒ¨í•œ ì‘ë‹µ í‘œì‹œ (ìš”ì²­ ì œí•œ ë“±)
                if result.get('rate_limited'):
                    st.error(f"â±ï¸ {result['final_response']}")
                    st.session_state.rate_limit_hits += 1
                else:
                    st.error(f"âŒ {result['final_response']}")
            
            st.rerun()

def main():
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ai_system = FreePlanAISystem()
    
    # ì‚¬ì´ë“œë°” í‘œì‹œ
    ai_system.display_beautiful_sidebar()
    
    # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    ai_system.display_beautiful_chat()
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: #6c757d; font-size: 0.9rem;'>"
        "copyright Â©ï¸ 2025. Synox Studios"
        "</div>", 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()