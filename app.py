import streamlit as st
import google.generativeai as genai
import sqlite3
import hashlib
import requests
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import os
import sys

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('chatbot.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="JiNu Hybrid",
    page_icon="â™»ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

class UltimateHybridChatbot:
    def __init__(self):
        self.setup_apis()
        self.setup_database()
        self.setup_session_state()
        logger.info("í•˜ì´ë¸Œë¦¬ë“œ ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_apis(self):
        """ëª¨ë“  API ì„¤ì •"""
        try:
            # Gemini API ì„¤ì •
            gemini_key = os.getenv("GEMINI_API_KEY")
            if gemini_key:
                genai.configure(api_key=gemini_key)
                self.gemini_available = True
                logger.info("Gemini API ì„¤ì • ì™„ë£Œ")
            else:
                self.gemini_available = False
                logger.warning("Gemini API í‚¤ ì—†ìŒ")
            
            # OpenRouter API ì„¤ì •
            self.openrouter_key = os.getenv("OPENROUTER_API_KEY")
            self.openrouter_available = bool(self.openrouter_key)
            
            if self.openrouter_available:
                logger.info("OpenRouter API ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"API ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
            st.error("API ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def setup_database(self):
        """ê°•ë ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            self.conn = sqlite3.connect('chatbot_website.db', check_same_thread=False)
            cursor = self.conn.cursor()
            
            # âœ… conversations í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    user_message TEXT,
                    bot_response TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    model_used TEXT,
                    response_time REAL,
                    intent_detected TEXT
                )
            ''')
            
            # âœ… users í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS users (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT UNIQUE,
                    first_visit DATETIME,
                    last_visit DATETIME,
                    visit_count INTEGER DEFAULT 0,
                    total_messages INTEGER DEFAULT 0
                )
            ''')
            
            # âœ… performance í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    model_name TEXT,
                    response_time REAL,
                    success BOOLEAN,
                    error_message TEXT
                )
            ''')
            
            self.conn.commit()
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.error("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    def setup_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        if 'user_id' not in st.session_state:
            st.session_state.user_id = hashlib.md5(
                str(datetime.now().timestamp()).encode()
            ).hexdigest()
            self.track_user_visit()
        
        if 'chat_start_time' not in st.session_state:
            st.session_state.chat_start_time = datetime.now()
    
    def track_user_visit(self):
        """ì‚¬ìš©ì ë°©ë¬¸ ì¶”ì """
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT OR REPLACE INTO users 
                (session_id, first_visit, last_visit, visit_count, total_messages)
                VALUES (?, 
                       COALESCE((SELECT first_visit FROM users WHERE session_id=?), datetime('now')), 
                       datetime('now'), 
                       COALESCE((SELECT visit_count FROM users WHERE session_id=?), 0) + 1,
                       COALESCE((SELECT total_messages FROM users WHERE session_id=?), 0)
                )
            ''', (st.session_state.user_id, st.session_state.user_id, 
                  st.session_state.user_id, st.session_state.user_id))
            
            self.conn.commit()
            logger.info(f"ì‚¬ìš©ì ë°©ë¬¸ ê¸°ë¡: {st.session_state.user_id}")
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì¶”ì  ì˜¤ë¥˜: {e}")
    
    def detect_intent(self, user_input: str) -> Dict:
        """ê³ ê¸‰ ì˜ë„ ê°ì§€ ì‹œìŠ¤í…œ"""
        intents = {
            'creative': ['ì‘ì„±', 'ìƒì„±', 'ë§Œë“¤', 'ê¸€ì“°ê¸°', 'ì‹œ', 'ì´ì•¼ê¸°', 'ì°½ì˜'],
            'technical': ['ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°', 'ì•Œê³ ë¦¬ì¦˜', 'ê°œë°œ', 'ì„¤ê³„', 'íŒŒì´ì¬', 'ìë°”'],
            'factual': ['ë­ì•¼', 'ë¬´ì—‡', 'ì•Œë ¤ì¤˜', 'ì •ë³´', 'ì‚¬ì‹¤', 'ì •ì˜', 'ì˜ë¯¸'],
            'analytical': ['ë¶„ì„', 'ë¹„êµ', 'ì¥ë‹¨ì ', 'ì™œ', 'ì–´ë–»ê²Œ', 'ì›ì¸', 'ê²°ê³¼'],
            'casual': ['ì•ˆë…•', 'í•˜ì´', 'ì˜ì§€ë‚´', 'ê³ ë§ˆì›Œ', 'ã…‹ã…‹', 'ã…ã…', 'ë°˜ê°€ì›Œ']
        }
        
        detected_intents = []
        for intent, keywords in intents.items():
            if any(keyword in user_input for keyword in keywords):
                detected_intents.append(intent)
        
        # ë³µì¡ë„ ë¶„ì„
        complexity = 'high' if len(user_input.split()) > 10 else 'medium'
        complexity = 'low' if len(user_input.split()) < 3 else complexity
        
        return {
            'intents': detected_intents if detected_intents else ['general'],
            'complexity': complexity,
            'requires_context': len(user_input) > 20
        }
    
    def call_gemini_api(self, prompt: str, intent: str) -> str:
        """Gemini API í˜¸ì¶œ"""
        if not self.gemini_available:
            return "Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        try:
            start_time = time.time()
            
            # ì˜ë„ë³„ í”„ë¡¬í”„íŠ¸ ìµœì í™”
            intent_prompts = {
                'creative': "ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì‘ê°€ì…ë‹ˆë‹¤. ì°½ì˜ì ì´ê³  í¥ë¯¸ë¡œìš´ ë‚´ìš©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                'technical': "ë‹¹ì‹ ì€ ì „ë¬¸ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.",
                'factual': "ë‹¹ì‹ ì€ ì „ë¬¸ ë°±ê³¼ì‚¬ì „ì…ë‹ˆë‹¤. ì‚¬ì‹¤ì ì´ê³  ì •í™•í•œ ì •ë³´ë§Œ ì œê³µí•´ì£¼ì„¸ìš”.",
                'analytical': "ë‹¹ì‹ ì€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¹Šì´ ìˆê³  ì²´ê³„ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.",
                'casual': "ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ ì£¼ì„¸ìš”."
            }
            
            system_prompt = intent_prompts.get(intent, "ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
            
            full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì: {prompt}"
            
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(full_prompt)
            
            response_time = time.time() - start_time
            
            # ì„±ëŠ¥ ë¡œê¹…
            self.log_performance('gemini-2.5-flash', response_time, True, "")
            
            logger.info(f"Google API í˜¸ì¶œ ì„±ê³µ: {response_time:.2f}ì´ˆ")
            return response.text
            
        except Exception as e:
            error_msg = f"Gemini API ì˜¤ë¥˜: {str(e)}"
            logger.error(error_msg)
            self.log_performance('gemini-2.5-flash', 0, False, error_msg)
            return f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def call_openrouter_api(self, prompt: str) -> str:
        """OpenRouter API í˜¸ì¶œ (ë°±ì—…)"""
        if not self.openrouter_available:
            return "OpenRouter APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            start_time = time.time()
            
            url = "https://openrouter.ai/api/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {self.openrouter_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://your-website.com",
                "X-Title": "AI Chatbot Website"
            }
            
            data = {
                "model": "meta-llama/llama-3.1-8b-instruct:free",
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 1000
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                self.log_performance('llama-3.1-8b-instruct', response_time, True, "")
                logger.info(f"OpenRouter API í˜¸ì¶œ ì„±ê³µ: {response_time:.2f}ì´ˆ")
                return content
            else:
                error_msg = f"OpenRouter API ì˜¤ë¥˜: {response.status_code}"
                logger.error(error_msg)
                self.log_performance('llama-3.1-8b-instruct', response_time, False, error_msg)
                return f"OpenRouter API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}"
                
        except Exception as e:
            error_msg = f"OpenRouter API ì˜ˆì™¸: {str(e)}"
            logger.error(error_msg)
            self.log_performance('llama-3.1-8b-instruct', 0, False, error_msg)
            return f"OpenRouter API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def log_performance(self, model_name: str, response_time: float, success: bool, error_message: str = ""):
        """ì„±ëŠ¥ ë¡œê¹…"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT INTO performance (model_name, response_time, success, error_message)
                VALUES (?, ?, ?, ?)
            ''', (model_name, response_time, success, error_message))
            self.conn.commit()
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ë¡œê¹… ì˜¤ë¥˜: {e}")
    
    def hybrid_response_generation(self, user_input: str) -> Dict:
        """í•˜ì´ë¸Œë¦¬ë“œ ì‘ë‹µ ìƒì„± ì‹œìŠ¤í…œ"""
        start_time = time.time()
        intent_analysis = self.detect_intent(user_input)
        primary_intent = intent_analysis['intents'][0]
        
        responses = {}
        models_used = []
        
        # 1. ê¸°ë³¸: Gemini API ì‹œë„
        if self.gemini_available:
            gemini_response = self.call_gemini_api(user_input, primary_intent)
            responses['gemini'] = gemini_response
            models_used.append('gemini')
        
        # 2. ë°±ì—…: OpenRouter ì‹œë„
        if self.openrouter_available and ('gemini' not in responses or "ì˜¤ë¥˜" in responses['gemini']):
            openrouter_response = self.call_openrouter_api(user_input)
            responses['openrouter'] = openrouter_response
            models_used.append('openrouter')
        
        # 3. ìµœí›„ì˜ ë°±ì—…: ë¡œì»¬ ì‘ë‹µ
        if not responses or all("ì˜¤ë¥˜" in response for response in responses.values()):
            responses['fallback'] = self.generate_fallback_response(user_input, intent_analysis)
            models_used.append('fallback')
        
        total_time = time.time() - start_time
        
        return {
            'responses': responses,
            'models_used': models_used,
            'processing_time': total_time,
            'intent_analysis': intent_analysis,
            'final_response': self.select_best_response(responses, intent_analysis)
        }
    
    def generate_fallback_response(self, user_input: str, intent_analysis: Dict) -> str:
        """í´ë°± ì‘ë‹µ ìƒì„±"""
        fallback_responses = {
            'creative': "ì œê°€ ì°½ì˜ì ì¸ ë‚´ìš©ì„ ìƒì„±í•˜ë ¤ë©´ API ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ëŠ” ì—°ê²°ì— ë¬¸ì œê°€ ìˆì–´ ê°„ë‹¨í•œ ë‹µë³€ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            'technical': "ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì—ëŠ” ì •í™•í•œ API ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ API ì—°ê²°ì„ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.",
            'factual': "ì‚¬ì‹¤ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ì„  API ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            'general': "í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ìœ¼ë¡œ ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        }
        
        for intent in intent_analysis['intents']:
            if intent in fallback_responses:
                return fallback_responses[intent]
        
        return fallback_responses['general']
    
    def select_best_response(self, responses: Dict, intent_analysis: Dict) -> str:
        """ìµœì ì˜ ì‘ë‹µ ì„ íƒ"""
        # Gemini ì‘ë‹µì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        if 'gemini' in responses and responses['gemini'] and "ì˜¤ë¥˜" not in responses['gemini']:
            return responses['gemini']
        
        # OpenRouter ì‘ë‹µ
        if 'openrouter' in responses and responses['openrouter']:
            return responses['openrouter']
        
        # í´ë°± ì‘ë‹µ
        if 'fallback' in responses:
            return responses['fallback']
        
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def save_conversation(self, user_input: str, result: Dict):
        """ëŒ€í™” ì €ì¥"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT INTO conversations 
                (session_id, user_message, bot_response, model_used, response_time, intent_detected)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                st.session_state.user_id,
                user_input,
                result['final_response'],
                ','.join(result['models_used']),
                result['processing_time'],
                ','.join(result['intent_analysis']['intents'])
            ))
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ìˆ˜ ì—…ë°ì´íŠ¸
            cursor.execute('''
                UPDATE users SET total_messages = total_messages + 1 
                WHERE session_id = ?
            ''', (st.session_state.user_id,))
            
            self.conn.commit()
            logger.info(f"ëŒ€í™” ì €ì¥ ì™„ë£Œ: {user_input[:50]}...")
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def get_conversation_stats(self) -> Dict:
        """ëŒ€í™” í†µê³„ ì¡°íšŒ"""
        try:
            cursor = self.conn.cursor()
            
            # ì´ ëŒ€í™” ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM conversations")
            total_conversations = cursor.fetchone()[0] or 0
            
            # ì´ ì‚¬ìš©ì ìˆ˜
            cursor.execute("SELECT COUNT(DISTINCT session_id) FROM users")
            total_users = cursor.fetchone()[0] or 0
            
            # ì˜¤ëŠ˜ ëŒ€í™” ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM conversations WHERE DATE(timestamp) = DATE('now')")
            today_conversations = cursor.fetchone()[0] or 0
            
            # í‰ê·  ì‘ë‹µ ì‹œê°„
            cursor.execute("SELECT AVG(response_time) FROM conversations WHERE response_time IS NOT NULL")
            avg_response_time = cursor.fetchone()[0] or 0
            
            return {
                'total_conversations': total_conversations,
                'total_users': total_users,
                'today_conversations': today_conversations,
                'avg_response_time': avg_response_time
            }
            
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {
                'total_conversations': 0,
                'total_users': 0,
                'today_conversations': 0,
                'avg_response_time': 0
            }
    
    def display_sidebar(self):
        """ê³ ê¸‰ ì‚¬ì´ë“œë°” í‘œì‹œ"""
        with st.sidebar:
            st.title("ğŸš€ AI ì±—ë´‡ ì»¨íŠ¸ë¡¤")
            
            # API ìƒíƒœ í‘œì‹œ
            st.subheader("ğŸ”Œ API ìƒíƒœ")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Google", "âœ…" if self.gemini_available else "âŒ")
            with col2:
                st.metric("OpenRouter", "âœ…" if self.openrouter_available else "âŒ")
            
            st.markdown("---")
            
            # ì‹¤ì‹œê°„ í†µê³„
            st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í†µê³„")
            stats = self.get_conversation_stats()
            
            st.metric("ì´ ëŒ€í™” ìˆ˜", f"{stats['total_conversations']:,}")
            st.metric("ì´ ì‚¬ìš©ì ìˆ˜", f"{stats['total_users']:,}")
            st.metric("ì˜¤ëŠ˜ ëŒ€í™”", f"{stats['today_conversations']:,}")
            st.metric("í‰ê·  ì‘ë‹µì‹œê°„", f"{stats['avg_response_time']:.2f}s")
            
            st.markdown("---")
            
            # ê´€ë¦¬ ê¸°ëŠ¥
            st.subheader("âš™ï¸ ê´€ë¦¬")
            
            if st.button("ğŸ—‘ï¸ í˜„ì¬ ëŒ€í™” ì§€ìš°ê¸°", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
            
            if st.button("ğŸ“Š ì„±ëŠ¥ ë¦¬í¬íŠ¸", use_container_width=True):
                self.show_performance_report()
            
            # ì‹œìŠ¤í…œ ì •ë³´
            st.markdown("---")
            st.markdown("""
            **ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´**
            - í•˜ì´ë¸Œë¦¬ë“œ AI ì—”ì§„
            - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
            - ìë™ ì¥ì•  ì¡°ì¹˜
            """)
    
    def show_performance_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ í‘œì‹œ"""
        try:
            cursor = self.conn.cursor()
            
            # ëª¨ë¸ë³„ ì„±ëŠ¥ í†µê³„
            cursor.execute('''
                SELECT model_name, 
                       AVG(response_time) as avg_time,
                       COUNT(*) as total_requests,
                       SUM(CASE WHEN success THEN 1 ELSE 0 END) as success_count
                FROM performance 
                GROUP BY model_name
            ''')
            
            performance_data = cursor.fetchall()
            
            with st.expander("ğŸ“ˆ ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸", expanded=True):
                st.subheader("ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ")
                
                for model, avg_time, total_requests, success_count in performance_data:
                    success_rate = (success_count / total_requests * 100) if total_requests > 0 else 0
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(f"{model}", f"{avg_time:.2f}s")
                    with col2:
                        st.metric("ìš”ì²­ ìˆ˜", total_requests)
                    with col3:
                        st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
                    
        except Exception as e:
            st.error(f"ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
    
    def display_chat_interface(self):
        """ê³ ê¸‰ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
        st.title(" JiNuhybrid")
        st.markdown("""
        **ìµœê°• ì„±ëŠ¥ì˜ í•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œ:**
        - ğŸ§  *Google AI**: Google ìµœì‹  ëª¨ë¸
        - ğŸ”„ **OpenRouter**: ê³ ê¸‰ì¶”ë¡  ëª¨ë¸(Claude Sonnet, Lema)
        - ğŸ¯ **ì§€ëŠ¥í˜• ë¼ìš°íŒ…**: ìƒí™©ì— ë§ëŠ” ìµœì  ëª¨ë¸ ì„ íƒ
        - âš¡ **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ì´ˆê³ ì† ì‘ë‹µ
        (ì‘ë‹µ ì§€ì—°ì€ í…ìŠ¤íŠ¸ ìƒì„±í•˜ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„ìœ¼ë¡œ í•˜ì´ë¸Œë¦¬ë“œ AIëŠ” ì‘ë‹µìƒì„±ì€ ë°”ë¡œí•©ë‹ˆë‹¤)
        """)
        
        # ì±„íŒ… ì»¨í…Œì´ë„ˆ
        chat_container = st.container()
        
        with chat_container:
            # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
                    
                    # ë©”íƒ€ì •ë³´ í‘œì‹œ (AI ì‘ë‹µì¸ ê²½ìš°)
                    if message["role"] == "assistant" and "metadata" in message:
                        with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
                            st.write(f"**ì‚¬ìš© ëª¨ë¸:** {message['metadata'].get('models_used', 'N/A')}")
                            st.write(f"**ì²˜ë¦¬ ì‹œê°„:** {message['metadata'].get('processing_time', 0):.2f}ì´ˆ")
                            st.write(f"**ì˜ë„ ë¶„ì„:** {', '.join(message['metadata'].get('intents', []))}")
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¤” í•˜ì´ë¸Œë¦¬ë“œ AIê°€ ë¶„ì„ ì¤‘..."):
                    result = self.hybrid_response_generation(prompt)
                
                # ì‘ë‹µ í‘œì‹œ
                st.markdown(result['final_response'])
                
                # ìƒì„¸ ì •ë³´
                with st.expander("ğŸ”§ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì‚¬ìš© ëª¨ë¸", ', '.join(result['models_used']))
                    with col2:
                        st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result['processing_time']:.2f}ì´ˆ")
                    with col3:
                        st.metric("ì§ˆë¬¸ ìœ í˜•", ', '.join(result['intent_analysis']['intents']))
                    
                    # ëª¨ë“  ì‘ë‹µ ë³´ê¸°
                    st.write("**ëª¨ë“  AI ì‘ë‹µ:**")
                    for model, response in result['responses'].items():
                        st.write(f"**{model.upper()}:** {response}")
            
            # ì„¸ì…˜ì— ë©”ì‹œì§€ ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": result['final_response'],
                "metadata": {
                    "models_used": result['models_used'],
                    "processing_time": result['processing_time'],
                    "intents": result['intent_analysis']['intents']
                }
            })
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            self.save_conversation(prompt, result)
            
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    try:
        # ì•± ì´ˆê¸°í™”
        chatbot = UltimateHybridChatbot()
        
        # ì‚¬ì´ë“œë°” í‘œì‹œ
        chatbot.display_sidebar()
        
        # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
        chatbot.display_chat_interface()
        
        # í‘¸í„°
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown(
                "<div style='text-align: center; color: gray;'>"
                "Copyright â“’ 2025. Synox Studios"
                "</div>", 
                unsafe_allow_html=True
            )
        
        # ì„¸ì…˜ ì‹œê°„ í‘œì‹œ
        session_duration = datetime.now() - st.session_state.chat_start_time
        st.sidebar.markdown(f"**ì„¸ì…˜ ì‹œê°„:** {str(session_duration).split('.')[0]}")
        
    except Exception as e:
        logger.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        st.error("ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì½˜ì†” ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
