import streamlit as st
import google.generativeai as genai
import requests
import sqlite3
import hashlib
import time
import logging
from datetime import datetime
from typing import Dict, List, Optional
import json
import os

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="JiNu hybrid AI",
    page_icon="ğŸ’ ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/your-repo',
        'About': "# ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ AI\n ìµœì ì˜ AI ëª¨ë¸ ìë™ ì„ íƒ ì‹œìŠ¤í…œ"
    }
)

# âœ… CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 3.5rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: 800;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #6c757d;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: 300;
    }
    .free-badge {
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);
        color: white;
        padding: 0.2rem 0.6rem;
        border-radius: 10px;
        font-size: 0.7rem;
        font-weight: bold;
        margin-left: 0.5rem;
        vertical-align: middle;
    }
    .model-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        margin: 0.5rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .intent-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 600;
        margin: 0.1rem;
    }
    .complexity-high { background: #ff6b6b; color: white; }
    .complexity-medium { background: #ffd93d; color: black; }
    .complexity-low { background: #6bcf7f; color: white; }
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        border-bottom-right-radius: 5px;
        margin: 0.5rem 0;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .assistant-message {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 15px;
        border-bottom-left-radius: 5px;
        border-left: 5px solid #667eea;
        margin: 0.5rem 0;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    .stats-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
        text-align: center;
    }
    .rate-limit-warning {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        color: #856404;
    }
    .metadata-box {
        margin-top: 1rem; 
        padding: 0.8rem; 
        background: white; 
        border-radius: 10px; 
        border: 1px solid #e0e0e0;
        font-size: 0.85rem;
    }
</style>
""", unsafe_allow_html=True)

class FreePlanAISystem:
    def __init__(self):
        self.setup_api_keys()
        self.setup_database()
        self.initialize_session_state()
        self.setup_rate_limiting()
        logger.info("í•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_api_keys(self):
        """API í‚¤ ì„¤ì •"""
        try:
            # Google Gemini
            if 'GEMINI_API_KEY' in st.secrets:
                genai.configure(api_key=st.secrets['GEMINI_API_KEY'])
                self.gemini_available = True
                logger.info("Gemini API ì„¤ì • ì™„ë£Œ")
            else:
                self.gemini_available = False # ìˆ˜ì •: ì˜¤íƒ€ ìˆ˜ì • (=I False -> = False)
                logger.warning("Gemini API í‚¤ ì—†ìŒ")
            
            # OpenRouter
            self.openrouter_key = st.secrets.get('OPENROUTER_API_KEY', '')
            self.openrouter_available = bool(self.openrouter_key)
            
            # DeepSeek
            self.deepseek_key = st.secrets.get('DEEPSEEK_API_KEY', '')
            self.deepseek_available = bool(self.deepseek_key)
                
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
            self.available_models = []
            if self.gemini_available: self.available_models.append('gemini')
            if self.openrouter_available: self.available_models.append('claude')
            if self.deepseek_available: self.available_models.append('deepseek')
                
            logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {self.available_models}")
                
        except Exception as e:
            logger.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
            st.error("API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def setup_rate_limiting(self):
        """ìš”ì²­ ì œí•œ ì„¤ì •"""
        self.rate_limits = {
            'gemini': {'count': 0, 'last_reset': time.time(), 'max_per_minute': 15},
            'claude': {'count': 0, 'last_reset': time.time(), 'max_per_minute': 10},
            'deepseek': {'count': 0, 'last_reset': time.time(), 'max_per_minute': 20}
        }
    
    def check_rate_limit(self, model: str) -> bool:
        """ìš”ì²­ ì œí•œ í™•ì¸"""
        current_time = time.time()
        limit_info = self.rate_limits[model]
        
        if current_time - limit_info['last_reset'] > 60:
            limit_info['count'] = 0
            limit_info['last_reset'] = current_time
        
        if limit_info['count'] >= limit_info['max_per_minute']:
            return False
        
        limit_info['count'] += 1
        return True
    
    def setup_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
        try:
            self.conn = sqlite3.connect('ai_system.db', check_same_thread=False)
            cursor = self.conn.cursor()
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    user_message TEXT,
                    bot_response TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    model_used TEXT,
                    intent_detected TEXT,
                    processing_time REAL,
                    tokens_used INTEGER,
                    rate_limited BOOLEAN DEFAULT FALSE
                )
            ''')
            self.conn.commit()
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    
    def initialize_session_state(self):
        """Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        if 'user_id' not in st.session_state:
            st.session_state.user_id = hashlib.md5(str(datetime.now().timestamp()).encode()).hexdigest()
        if 'conversation_count' not in st.session_state:
            st.session_state.conversation_count = 0
        if 'model_usage' not in st.session_state:
            st.session_state.model_usage = {}
        if 'rate_limit_hits' not in st.session_state:
            st.session_state.rate_limit_hits = 0

    def advanced_intent_analysis(self, user_input: str) -> Dict:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        intent_keywords = {
            'complex_reasoning': ['ë…¼ë¦¬', 'ì¶”ë¡ ', 'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'ë¹„íŒ', 'ì´ìœ ', 'ê·¼ê±°', 'ë³µì¡', 'ì‹¬ì¸µ'],
            'technical': ['ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°', 'ì•Œê³ ë¦¬ì¦˜', 'íŒŒì´ì¬', 'ìë°”', 'í•¨ìˆ˜', 'ì—ëŸ¬', 'ë””ë²„ê¹…', 'api', 'json'],
            'creative': ['ì‘ì„±', 'ìƒì„±', 'ê¸€ì“°ê¸°', 'ì‹œ', 'ì†Œì„¤', 'ì•„ì´ë””ì–´', 'ê¸°íš', 'ì°½ì‘'],
            'mathematical': ['ê³„ì‚°', 'ìˆ˜í•™', 'ê³µì‹', 'í™•ë¥ ', 'í†µê³„', 'ìˆ˜ì‹'],
            'research': ['ì—°êµ¬', 'ë…¼ë¬¸', 'ì´ë¡ ', 'ì—­ì‚¬', 'ê³¼í•™', 'ì¡°ì‚¬', 'ë°ì´í„°'],
        }
        
        intent_scores = {}
        user_lower = user_input.lower()
        
        for intent, keywords in intent_keywords.items():
            score = sum(10 for keyword in keywords if keyword in user_lower)
            if score > 0:
                intent_scores[intent] = score
        
        word_count = len(user_input.split())
        if word_count > 25: complexity = 'high'
        elif word_count > 7: complexity = 'medium'
        else: complexity = 'low'
        
        primary_intent = 'general'
        if intent_scores:
            primary_intent = max(intent_scores.items(), key=lambda x: x[1])[0]
        
        return {
            'primary_intent': primary_intent,
            'complexity': complexity,
            'intent_scores': intent_scores
        }

    def select_optimal_model(self, intent_analysis: Dict) -> Dict:
        """ì˜ë„ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ"""
        intent_model_mapping = {
            'complex_reasoning': {
                'primary': 'claude', 'backup': 'deepseek', 'fallback': 'gemini',
                'reason': 'ğŸ§  ë³µì¡í•œ ë…¼ë¦¬/ì¶”ë¡ ì—ëŠ” Claude 3.5ê°€ ìš°ìˆ˜', 'icon': 'ğŸ§ '
            },
            'technical': {
                'primary': 'deepseek', 'backup': 'gemini', 'fallback': 'claude',
                'reason': 'ğŸ’» ì½”ë“œ/ê¸°ìˆ  ë¬¸ì œì—ëŠ” DeepSeek V3ê°€ ìµœì í™”', 'icon': 'ğŸ’»'
            },
            'mathematical': {
                'primary': 'deepseek', 'backup': 'gemini', 'fallback': 'claude',
                'reason': 'ğŸ§® ìˆ˜í•™ì  ì—°ì‚°ì—ëŠ” DeepSeekê°€ ê°•ë ¥', 'icon': 'ğŸ§®'
            },
            'creative': {
                'primary': 'claude', 'backup': 'gemini', 'fallback': 'deepseek',
                'reason': 'ğŸ¨ ì°½ì˜ì  ì‘ë¬¸ì€ Claudeê°€ ë›°ì–´ë‚¨', 'icon': 'ğŸ¨'
            },
            'general': {
                'primary': 'gemini', 'backup': 'deepseek', 'fallback': 'claude',
                'reason': 'âš¡ ì¼ë°˜ ì§ˆë¬¸ì—ëŠ” ë¹ ë¥´ê³  ê²½ì œì ì¸ Gemini', 'icon': 'âš¡'
            }
        }
        
        primary_intent = intent_analysis['primary_intent']
        model_choice = intent_model_mapping.get(primary_intent, intent_model_mapping['general'])
        
        # ëª¨ë¸ ê°€ìš©ì„± ë° ì œí•œ ì²´í¬ ë¡œì§
        selected_model = None
        
        for tier in ['primary', 'backup', 'fallback']:
            candidate = model_choice[tier]
            if candidate in self.available_models and self.check_rate_limit(candidate):
                selected_model = candidate
                if tier != 'primary':
                    model_choice['reason'] += f" ({tier} ëª¨ë¸ ì‚¬ìš©)"
                break
        
        if not selected_model:
            for model in self.available_models:
                if self.check_rate_limit(model):
                    selected_model = model
                    model_choice['reason'] = f"âš ï¸ ê°€ìš© ëª¨ë¸ ì œí•œìœ¼ë¡œ {model} ì‚¬ìš©"
                    break
        
        model_choice['selected'] = selected_model
        return model_choice

    def call_gemini_api(self, prompt: str) -> Dict:
        """Gemini API í˜¸ì¶œ"""
        if not self.gemini_available: return {'success': False}
        try:
            start_time = time.time()
            # ìˆ˜ì •: 1.5-flash -> 2.5-flash (ì‚¬ìš©ê°€ëŠ¥í•œ apië¡œ)
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(prompt)
            
            st.session_state.model_usage['gemini'] = st.session_state.model_usage.get('gemini', 0) + 1
            return {
                'success': True,
                'content': response.text,
                'model': "Google Gemini Flash",
                'processing_time': time.time() - start_time,
                'tokens': len(prompt + response.text) // 4
            }
        except Exception as e:
            logger.error(f"Gemini API ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}

    def call_openrouter_api(self, prompt: str) -> Dict:
        """OpenRouter API í˜¸ì¶œ"""
        if not self.openrouter_available: return {'success': False}
        try:
            start_time = time.time()
            data = {
                "model": "anthropic/claude-3.5-sonnet",
                "messages": [{"role": "user", "content": prompt}],
            }
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={"Authorization": f"Bearer {self.openrouter_key}"},
                json=data, timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                st.session_state.model_usage['claude'] = st.session_state.model_usage.get('claude', 0) + 1
                return {
                    'success': True,
                    'content': result['choices'][0]['message']['content'],
                    'model': "Claude 3.5 Sonnet",
                    'processing_time': time.time() - start_time,
                    'tokens': result.get('usage', {}).get('total_tokens', 0)
                }
            return {'success': False, 'error': f"Status {response.status_code}"}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def call_deepseek_api(self, prompt: str) -> Dict:
        """DeepSeek API í˜¸ì¶œ"""
        if not self.deepseek_available: return {'success': False}
        try:
            start_time = time.time()
            data = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
            }
            response = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {self.deepseek_key}"},
                json=data, timeout=60
            )
            
            if response.status_code == 200:
                st.session_state.model_usage['deepseek'] = st.session_state.model_usage.get('deepseek', 0) + 1
                result = response.json()
                return {
                    'success': True,
                    'content': result['choices'][0]['message']['content'],
                    'model': "DeepSeek V3",
                    'processing_time': time.time() - start_time,
                    'tokens': result.get('usage', {}).get('total_tokens', 0)
                }
            return {'success': False, 'error': f"Status {response.status_code}"}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def intelligent_model_orchestration(self, user_input: str) -> Dict:
        """ëª¨ë¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰"""
        intent_analysis = self.advanced_intent_analysis(user_input)
        model_choice = self.select_optimal_model(intent_analysis)
        selected_model = model_choice['selected']
        
        response = {'success': False}
        
        if selected_model == 'claude':
            response = self.call_openrouter_api(user_input)
        elif selected_model == 'deepseek':
            response = self.call_deepseek_api(user_input)
        elif selected_model == 'gemini':
            response = self.call_gemini_api(user_input)
            
        # ì‹¤íŒ¨ ì‹œ ë°±ì—… ì‹œë„ (ê°„ì†Œí™”ëœ ë¡œì§)
        if not response.get('success') and selected_model != 'gemini' and self.gemini_available:
             response = self.call_gemini_api(user_input)
             selected_model = 'gemini'
             model_choice['reason'] += " (ì˜¤ë¥˜ë¡œ ì¸í•´ Gemini ë°±ì—… ì‚¬ìš©)"

        if response.get('success'):
            return {
                'success': True,
                'content': response['content'],
                'model_name': response['model'],
                'intent_analysis': intent_analysis,
                'model_reason': model_choice['reason'],
                'processing_time': response['processing_time'],
                'tokens_used': response['tokens'],
                'model_icon': model_choice['icon']
            }
        else:
            return {'success': False, 'error': "ëª¨ë“  ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨"}

    def display_beautiful_sidebar(self):
        """ì‚¬ì´ë“œë°” UI"""
        with st.sidebar:
            st.markdown('<div class="main-header">ğŸ’ JiNu AI</div>', unsafe_allow_html=True)
            st.markdown('<div style="text-align: center; margin-bottom: 1rem;"><span class="free-badge">HYBRID ENGINE</span></div>', unsafe_allow_html=True)
            
            st.markdown("### ğŸ”§ ì—°ê²° ìƒíƒœ")
            c1, c2, c3 = st.columns(3)
            c1.metric("Gemini", "ON" if self.gemini_available else "OFF")
            c2.metric("Claude", "ON" if self.openrouter_available else "OFF")
            c3.metric("DeepSeek", "ON" if self.deepseek_available else "OFF")
            
            st.markdown("---")
            st.markdown("### ğŸ“ˆ ì‚¬ìš© í†µê³„")
            st.markdown(f"""
            <div class="stats-card">
                <div style="font-size: 2rem; font-weight: bold; color: #667eea;">{st.session_state.conversation_count}</div>
                <div style="color: #6c757d;">ì´ ëŒ€í™” ìˆ˜</div>
            </div>
            """, unsafe_allow_html=True)
            
            if st.session_state.model_usage:
                st.markdown("#### ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰")
                for m, c in st.session_state.model_usage.items():
                    st.caption(f"{m.title()}: {c}íšŒ")

            st.markdown("---")
            st.markdown("### ğŸ† ëª¨ë¸ ë¼ì¸ì—…")
            
            # ìˆ˜ì •: type í‚¤ ì¶”ê°€í•˜ì—¬ KeyError ë°©ì§€
            free_model_specs = [
                {"icon": "ğŸ§ ", "name": "Claude 3.5", "desc": "ë…¼ë¦¬, ì‘ë¬¸", "type": "CREDIT"},
                {"icon": "âš¡", "name": "Gemini Flash", "desc": "ë¹ ë¥¸ ì‘ë‹µ", "type": "FREE"}, 
                {"icon": "ğŸ’»", "name": "DeepSeek V3", "desc": "ì½”ë”©, ìˆ˜í•™", "type": "FREE"}
            ]
            
            for spec in free_model_specs:
                st.markdown(f"""
                <div class="model-card">
                    <div style="display: flex; justify-content: space-between;">
                        <div>{spec['icon']} <strong>{spec['name']}</strong></div>
                        <span class="free-badge">{spec['type']}</span>
                    </div>
                    <div style="font-size: 0.8rem; color: #666; margin-top: 4px;">{spec['desc']}</div>
                </div>
                """, unsafe_allow_html=True)
            
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°", use_container_width=True):
                st.session_state.messages = []
                st.session_state.conversation_count = 0
                st.rerun()

    def display_beautiful_chat(self):
        """ì±„íŒ… UI"""
        st.markdown('<div class="main-header">ğŸ’  JiNu Hybrid AI</div>', unsafe_allow_html=True)
        st.markdown('<div class="sub-header">ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)
        
        # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                st.markdown(f"""
                <div style="display: flex; justify-content: flex-end;">
                    <div class="user-message">{msg["content"]}</div>
                </div>
                """, unsafe_allow_html=True)
            else:
                meta = msg.get('metadata', {})
                meta_html = ""
                if meta:
                    meta_html = f"""
                    <div class="metadata-box">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <span style="color: #667eea; font-weight: bold;">{meta.get('model_icon', 'ğŸ¤–')} {meta['model_name']}</span>
                            <span class="intent-badge complexity-{meta['intent_analysis']['complexity']}">{meta['intent_analysis']['primary_intent']}</span>
                        </div>
                        <hr style="margin: 0.5rem 0; opacity: 0.2;">
                        <div style="color: #666;">ğŸ’¡ {meta['model_reason']}</div>
                        <div style="text-align: right; font-size: 0.7rem; color: #999; margin-top: 0.3rem;">â±ï¸ {meta['response_time']:.2f}s | {meta['tokens_used']} tokens</div>
                    </div>
                    """
                
                st.markdown(f"""
                <div style="display: flex; justify-content: flex-start;">
                    <div class="assistant-message" style="max-width: 85%;">
                        {msg["content"]}
                        {meta_html}
                    </div>
                </div>
                """, unsafe_allow_html=True)

        # ì…ë ¥ì°½
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: íŒŒì´ì¬ ì½”ë“œ ì§œì¤˜, ì‹œ ì¨ì¤˜, ì´ê²Œ ë­ì•¼?)"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.rerun()

        # ë‹µë³€ ìƒì„± ë¡œì§ (ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ìœ ì €ì¼ ê²½ìš° ì‹¤í–‰)
        if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
            with st.spinner("ğŸ¤” í•˜ì´ë¸Œë¦¬ë“œ AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                result = self.intelligent_model_orchestration(st.session_state.messages[-1]["content"])
                
                if result['success']:
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": result['content'],
                        "metadata": result
                    })
                    
                    # DB ì €ì¥
                    try:
                        cursor = self.conn.cursor()
                        cursor.execute('''
                            INSERT INTO conversations 
                            (session_id, user_message, bot_response, model_used, intent_detected, processing_time, tokens_used)
                            VALUES (?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            st.session_state.user_id,
                            st.session_state.messages[-2]["content"],
                            result['content'],
                            result['model_name'],
                            result['intent_analysis']['primary_intent'],
                            result['processing_time'],
                            result['tokens_used']
                        ))
                        self.conn.commit()
                        st.session_state.conversation_count += 1
                    except Exception as e:
                        logger.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")
                        
                    st.rerun()
                else:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('error', 'Unknown error')}")

def main():
    ai_system = FreePlanAISystem()
    ai_system.display_beautiful_sidebar()
    ai_system.display_beautiful_chat()

if __name__ == "__main__":
    main()
