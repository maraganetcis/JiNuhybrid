import streamlit as st
import google.generativeai as genai
import requests
from typing import Dict, List
import json
import time
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œ",
    page_icon="ğŸ§ ",
    layout="wide"
)

class StreamlitAISystem:
    def __init__(self):
        self.setup_api_keys()
        self.initialize_session_state()
    
    def setup_api_keys(self):
        """Streamlit secretsì—ì„œ API í‚¤ ì„¤ì •"""
        try:
            # Google Gemini
            if 'GOOGLE_API_KEY' in st.secrets:
                genai.configure(api_key=st.secrets['GOOGLE_API_KEY'])
                self.gemini_available = True
            else:
                self.gemini_available = False
            
            # OpenRouter
            self.openrouter_key = st.secrets.get('OPENROUTER_API_KEY', '')
            self.openrouter_available = bool(self.openrouter_key)
            
            # DeepSeek
            self.deepseek_key = st.secrets.get('DEEPSEEK_API_KEY', '')
            self.deepseek_available = bool(self.deepseek_key)
            
        except Exception as e:
            st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        if 'conversation_history' not in st.session_state:
            st.session_state.conversation_history = []
        
        if 'total_cost' not in st.session_state:
            st.session_state.total_cost = 0.0
            
        if 'model_usage' not in st.session_state:
            st.session_state.model_usage = {}

    def advanced_intent_analysis(self, user_input: str) -> Dict:
        """ê³ ê¸‰ ì˜ë„ ë¶„ì„ ì‹œìŠ¤í…œ - ì²˜ìŒ ì½”ë“œ ê¸°ì¤€"""
        intent_keywords = {
            'complex_reasoning': [
                'ë…¼ë¦¬', 'ì¶”ë¡ ', 'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'íŒë‹¨', 'ê²°ë¡ ', 'ê°€ì •',
                'ì „ì œ', 'ë…¼ì¦', 'íƒ€ë‹¹ì„±', 'ë¹„íŒì ', 'ì‚¬ê³ ', 'ì´ìœ ', 'ê·¼ê±°',
                'ë³µì¡í•œ', 'ë‚œì´ë„', 'ì‹¬ì¸µ', 'ë‹¤ë‹¨ê³„', 'ì¢…í•©', 'í†µí•©'
            ],
            'technical': ['ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°', 'ì•Œê³ ë¦¬ì¦˜', 'ê°œë°œ', 'ì„¤ê³„', 'íŒŒì´ì¬', 'ìë°”'],
            'creative': ['ì‘ì„±', 'ìƒì„±', 'ë§Œë“¤', 'ê¸€ì“°ê¸°', 'ì‹œ', 'ì´ì•¼ê¸°', 'ì°½ì˜'],
            'mathematical': ['ê³„ì‚°', 'ìˆ˜í•™', 'ê³µì‹', 'ë°©ì •ì‹', 'í†µê³„', 'í™•ë¥ ', 'ë¯¸ë¶„'],
            'research': ['ì—°êµ¬', 'ë…¼ë¬¸', 'ì°¸ê³ ë¬¸í—Œ', 'í•™ìˆ ', 'ì´ë¡ ', 'ì‹¤í—˜', 'ë°ì´í„°'],
            'factual': ['ë­ì•¼', 'ë¬´ì—‡', 'ì•Œë ¤ì¤˜', 'ì •ë³´', 'ì‚¬ì‹¤', 'ì •ì˜'],
            'casual': ['ì•ˆë…•', 'í•˜ì´', 'ì˜ì§€ë‚´', 'ê³ ë§ˆì›Œ', 'ë°˜ê°€ì›Œ']
        }
        
        # ì˜ë„ ì ìˆ˜ ê³„ì‚°
        intent_scores = {}
        user_lower = user_input.lower()
        
        for intent, keywords in intent_keywords.items():
            score = sum(10 for keyword in keywords if keyword in user_lower)
            if score > 0:
                intent_scores[intent] = score
        
        # ë³µì¡ë„ ë¶„ì„ ê°•í™”
        word_count = len(user_input.split())
        has_complex_indicators = any(word in user_lower for word in [
            'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'ë…¼ë¦¬', 'ì¶”ë¡ ', 'ì „ì œ', 'ê²°ë¡ '
        ])
        
        if word_count > 20 or has_complex_indicators:
            complexity = 'very_high'
        elif word_count > 12:
            complexity = 'high'
        elif word_count > 6:
            complexity = 'medium'
        else:
            complexity = 'low'
        
        # ì£¼ìš” ì˜ë„ ì„ íƒ (ë³µì¡í•œ ì¶”ë¡  ìš°ì„ )
        primary_intent = 'general'
        if intent_scores:
            if 'complex_reasoning' in intent_scores:
                primary_intent = 'complex_reasoning'
            else:
                primary_intent = max(intent_scores.items(), key=lambda x: x[1])[0]
        
        return {
            'primary_intent': primary_intent,
            'all_intents': list(intent_scores.keys()),
            'intent_scores': intent_scores,
            'complexity': complexity,
            'word_count': word_count,
            'is_complex': complexity in ['high', 'very_high']
        }

    def select_optimal_model(self, intent_analysis: Dict) -> Dict:
        """ìµœì ì˜ AI ëª¨ë¸ ì„ íƒ - ì²˜ìŒ ì½”ë“œ ê¸°ì¤€"""
        intent_model_mapping = {
            'complex_reasoning': {
                'primary': 'claude',
                'reason': 'ğŸ§  ë³µì¡í•œ ì¶”ë¡ ì—ëŠ” Claude 3.5 Sonnetì´ ê°€ì¥ ìš°ìˆ˜í•¨',
                'backup': 'gemini_advanced'
            },
            'technical': {
                'primary': 'gemini',
                'reason': 'ğŸ”§ ê¸°ìˆ /ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” Geminiê°€ ìµœì í™”ë¨',
                'backup': 'claude'
            },
            'mathematical': {
                'primary': 'gemini_advanced',
                'reason': 'ğŸ§® ìˆ˜í•™ì  ì¶”ë¡ ì—ëŠ” Gemini Advancedê°€ ì •í™•ë„ ë†’ìŒ',
                'backup': 'claude'
            },
            'research': {
                'primary': 'claude', 
                'reason': 'ğŸ“Š ì—°êµ¬/í•™ìˆ  ë¶„ì„ì—ëŠ” Claudeì˜ ê¹Šì€ ì´í•´ë ¥ì´ ì í•©',
                'backup': 'gemini_advanced'
            },
            'analytical': {
                'primary': 'gemini_advanced',
                'reason': 'ğŸ” ë¶„ì„ì  ì‚¬ê³ ì—ëŠ” Geminiì˜ ë…¼ë¦¬ë ¥ì´ ë›°ì–´ë‚¨',
                'backup': 'claude'
            },
            'creative': {
                'primary': 'claude',
                'reason': 'ğŸ¨ ì°½ì˜ì  ì‚¬ê³ ì—ëŠ” Claudeì˜ ìœ ì—°ì„±ì´ ì¢‹ìŒ',
                'backup': 'gemini'
            },
            'general': {
                'primary': 'gemini',
                'reason': 'âš¡ ì¼ë°˜ ì§ˆë¬¸ì—ëŠ” Geminiì˜ ë¹ ë¥¸ ì‘ë‹µì´ ì í•©',
                'backup': 'claude'
            }
        }
        
        # ë³µì¡ë„ê°€ ë§¤ìš° ë†’ìœ¼ë©´ ë³µì¡í•œ ì¶”ë¡  ëª¨ë¸ ê°•ì œ ì‚¬ìš©
        if intent_analysis['complexity'] == 'very_high':
            primary_intent = 'complex_reasoning'
        else:
            primary_intent = intent_analysis['primary_intent']
        
        model_choice = intent_model_mapping.get(primary_intent, intent_model_mapping['general'])
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
        if model_choice['primary'] == 'claude' and not self.openrouter_available:
            model_choice['primary'] = model_choice['backup']
        elif model_choice['primary'] == 'gemini_advanced' and not self.gemini_available:
            model_choice['primary'] = 'gemini'
        
        return model_choice

    def call_advanced_models(self, prompt: str, intent: str, model_type: str) -> Dict:
        """ê³ ê¸‰ ëª¨ë¸ í˜¸ì¶œ - ë³µì¡í•œ ì¶”ë¡  íŠ¹í™” (ì²˜ìŒ ì½”ë“œ ê¸°ì¤€)"""
        
        reasoning_prompts = {
            'complex_reasoning': """
            ë‹¹ì‹ ì€ ë…¼ë¦¬ì  ì¶”ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì ‘ê·¼í•´ì£¼ì„¸ìš”:
            1. ë¬¸ì œì˜ í•µì‹¬ ìš”ì†Œ ë¶„ì„
            2. ê°€ì •ê³¼ ì „ì œ í™•ì¸  
            3. ë…¼ë¦¬ì  ì—°ê²°ê³ ë¦¬ ë„ì¶œ
            4. ê²°ë¡  ë„ì¶œ ë° ê²€ì¦
            
            ì§ˆë¬¸: {prompt}
            """,
            'mathematical': """
            ë‹¹ì‹ ì€ ìˆ˜í•™ì  ì‚¬ê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•´ì£¼ì„¸ìš”:
            1. ë¬¸ì œ ì´í•´ ë° ë³€ìˆ˜ ì •ì˜
            2. ê´€ë ¨ ê³µì‹/ì´ë¡  ì ìš©
            3. ë‹¨ê³„ë³„ ê³„ì‚°
            4. ê²°ê³¼ ê²€ì¦
            
            ì§ˆë¬¸: {prompt}
            """,
            'technical': """
            ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤:
            1. ë¬¸ì œ ë¶„ì„ ë° ìš”êµ¬ì‚¬í•­ ì´í•´
            2. ìµœì ì˜ ì†”ë£¨ì…˜ ì„¤ê³„
            3. ì‹¤ìš©ì ì¸ ì½”ë“œ êµ¬í˜„
            4. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ë°©ë²• ì œì‹œ
            
            ì§ˆë¬¸: {prompt}
            """
        }
        
        specialized_prompt = reasoning_prompts.get(
            intent, 
            "ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”: {prompt}"
        ).format(prompt=prompt)
        
        try:
            if model_type in ['gemini', 'gemini_advanced'] and self.gemini_available:
                if model_type == 'gemini_advanced':
                    model = genai.GenerativeModel('gemini-1.5-pro')
                else:
                    model = genai.GenerativeModel('gemini-1.0-pro')
                
                response = model.generate_content(specialized_prompt)
                
                return {
                    'success': True,
                    'content': response.text,
                    'model': 'Gemini ' + ('Advanced' if model_type == 'gemini_advanced' else 'Flash'),
                    'tokens': len(prompt.split()) + len(response.text.split())
                }
                
            elif model_type == 'claude' and self.openrouter_available:
                data = {
                    "model": "anthropic/claude-3.5-sonnet",
                    "messages": [{"role": "user", "content": specialized_prompt}],
                    "max_tokens": 2000,
                    "temperature": 0.3
                }
                
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers={"Authorization": f"Bearer {self.openrouter_key}"},
                    json=data,
                    timeout=45
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    tokens = result.get('usage', {}).get('total_tokens', 0)
                    
                    return {
                        'success': True,
                        'content': content,
                        'model': 'Claude 3.5 Sonnet',
                        'tokens': tokens
                    }
                else:
                    return {'success': False, 'error': f'Claude API ì˜¤ë¥˜: {response.status_code}'}
            
            elif model_type == 'deepseek' and self.deepseek_available:
                data = {
                    "model": "deepseek-chat",
                    "messages": [{"role": "user", "content": specialized_prompt}],
                    "max_tokens": 2000,
                    "temperature": 0.3
                }
                
                response = requests.post(
                    "https://api.deepseek.com/chat/completions",
                    headers={"Authorization": f"Bearer {self.deepseek_key}"},
                    json=data,
                    timeout=45
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    tokens = result.get('usage', {}).get('total_tokens', 0)
                    
                    return {
                        'success': True,
                        'content': content,
                        'model': 'DeepSeek V3',
                        'tokens': tokens
                    }
                else:
                    return {'success': False, 'error': f'DeepSeek API ì˜¤ë¥˜: {response.status_code}'}
            
            return {'success': False, 'error': 'ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.'}
                
        except Exception as e:
            return {'success': False, 'error': f'ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}'}

def display_intent_analysis(intent_analysis: Dict):
    """ì˜ë„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ - ì²˜ìŒ UI ë””ìì¸ëŒ€ë¡œ"""
    st.sidebar.markdown("### ğŸ¯ ì˜ë„ ë¶„ì„ ê²°ê³¼")
    
    # ì£¼ìš” ì˜ë„
    intent_icons = {
        'complex_reasoning': 'ğŸ§ ',
        'technical': 'ğŸ”§', 
        'creative': 'ğŸ¨',
        'mathematical': 'ğŸ§®',
        'research': 'ğŸ“Š',
        'factual': 'â„¹ï¸',
        'casual': 'ğŸ’¬',
        'general': 'âš¡'
    }
    
    primary_intent = intent_analysis['primary_intent']
    icon = intent_icons.get(primary_intent, 'âš¡')
    
    st.sidebar.markdown(f"**ì£¼ìš” ì˜ë„**: {icon} {primary_intent}")
    st.sidebar.markdown(f"**ë³µì¡ë„**: {intent_analysis['complexity']}")
    st.sidebar.markdown(f"**ë‹¨ì–´ ìˆ˜**: {intent_analysis['word_count']}")
    
    # ëª¨ë“  ì˜ë„ ì ìˆ˜
    if intent_analysis['intent_scores']:
        st.sidebar.markdown("**ì˜ë„ ì ìˆ˜**:")
        for intent, score in intent_analysis['intent_scores'].items():
            icon = intent_icons.get(intent, 'âš¡')
            st.sidebar.markdown(f"- {icon} {intent}: {score}ì ")

def display_model_selection(model_choice: Dict, intent_analysis: Dict):
    """ëª¨ë¸ ì„ íƒ ì •ë³´ í‘œì‹œ - ì²˜ìŒ UI ë””ìì¸ëŒ€ë¡œ"""
    st.sidebar.markdown("### ğŸ¤– ëª¨ë¸ ì„ íƒ ì •ë³´")
    
    model_icons = {
        'claude': 'ğŸ§ ',
        'gemini': 'ğŸ”§',
        'gemini_advanced': 'ğŸ§®',
        'deepseek': 'ğŸ’°'
    }
    
    primary_model = model_choice['primary']
    icon = model_icons.get(primary_model, 'âš¡')
    
    st.sidebar.markdown(f"**ì„ íƒëœ ëª¨ë¸**: {icon} {primary_model}")
    st.sidebar.markdown(f"**ì„ íƒ ì´ìœ **: {model_choice['reason']}")
    
    # ë³µì¡ë„ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ ë¡œì§ í‘œì‹œ
    st.sidebar.markdown("### âš™ï¸ ëª¨ë¸ ì„ íƒ ë¡œì§")
    if intent_analysis['is_complex']:
        if intent_analysis['primary_intent'] == 'complex_reasoning':
            st.sidebar.markdown("`model = 'claude'  # ê°€ì¥ ê°•ë ¥í•œ ì¶”ë¡  ëª¨ë¸`")
        elif intent_analysis['primary_intent'] == 'mathematical':
            st.sidebar.markdown("`model = 'gemini_advanced'  # ìˆ˜í•™ì  ì¶”ë¡  íŠ¹í™”`")
        else:
            st.sidebar.markdown("`model = 'claude'  # ì¼ë°˜ì  ë³µì¡ ì¶”ë¡ `")
    else:
        st.sidebar.markdown("`model = 'gemini'  # ì¼ë°˜ ì§ˆë¬¸ìš©`")

def display_model_comparison():
    """ëª¨ë¸ ë¹„êµí‘œ í‘œì‹œ - ì²˜ìŒ UI ë””ìì¸ëŒ€ë¡œ"""
    st.sidebar.markdown("### ğŸ’¡ ëª¨ë¸ ì¶”ë¡  ê°•ì ")
    
    comparison_data = {
        "ëª¨ë¸": ["Claude 3.5 Sonnet", "Gemini Thinking", "Llama 3 70B"],
        "ì¶”ë¡  ê°•ì ": ["ë…¼ë¦¬ì  ì¼ê´€ì„±, ë¹„íŒì  ì‚¬ê³ ", "ì²´ê³„ì  ì ‘ê·¼, ë‹¨ê³„ì  ì¶”ë¡ ", "ê´‘ë²”ìœ„í•œ ì§€ì‹ í†µí•©"],
        "ìµœì  ì‚¬ìš©ì²˜": ["ì² í•™ì  ë…¼ì¦, ë³µì¡í•œ ë¶„ì„", "ìˆ˜í•™ì  ë¬¸ì œ, ì•Œê³ ë¦¬ì¦˜", "ì—°êµ¬ ë¶„ì„, ì¢…í•©ì  íŒë‹¨"]
    }
    
    for i in range(len(comparison_data["ëª¨ë¸"])):
        st.sidebar.markdown(f"**{comparison_data['ëª¨ë¸'][i]}**")
        st.sidebar.markdown(f"- ê°•ì : {comparison_data['ì¶”ë¡  ê°•ì '][i]}")
        st.sidebar.markdown(f"- ì‚¬ìš©ì²˜: {comparison_data['ìµœì  ì‚¬ìš©ì²˜'][i]}")

def main():
    st.title("ğŸ§  ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ì— ìµœì í™”ëœ AI ëª¨ë¸")
    
    st.markdown("""
    **í˜„ì¬ ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ì—ëŠ” ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ëª¨ë¸ë“¤ì´ ì‚¬ìš©ë©ë‹ˆë‹¤:**
    
    ğŸ† **ë³µì¡í•œ ì¶”ë¡ ì— ê°€ì¥ ê°•ë ¥í•œ ëª¨ë¸ë“¤**
    1. Google Gemini 2.0/2.5 Pro ì‹œë¦¬ì¦ˆ
    2. Anthropic Claude 3.5 Sonnet  
    3. Meta Llama 3 70B
    """)
    
    # AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ai_system = StreamlitAISystem()
    
    # ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ë¹„êµí‘œ í‘œì‹œ
    display_model_comparison()
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    st.markdown("---")
    st.subheader("ğŸ’¬ ëŒ€í™”í•˜ê¸°")
    
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "model" in message:
                st.caption(f"ëª¨ë¸: {message['model']}")
            if "intent" in message:
                st.caption(f"ì˜ë„: {message['intent']}")
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë³µì¡í•œ ì¶”ë¡  ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ì˜ë„ ë¶„ì„ ë° ëª¨ë¸ ì„ íƒ
        with st.spinner("ì˜ë„ ë¶„ì„ ì¤‘..."):
            intent_analysis = ai_system.advanced_intent_analysis(prompt)
            model_choice = ai_system.select_optimal_model(intent_analysis)
        
        # ì‚¬ì´ë“œë°”ì— ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        display_intent_analysis(intent_analysis)
        display_model_selection(model_choice, intent_analysis)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            
            with st.spinner(f"{model_choice['primary']} ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„± ì¤‘..."):
                response = ai_system.call_advanced_models(
                    prompt, 
                    intent_analysis['primary_intent'],
                    model_choice['primary']
                )
                
                if response['success']:
                    # ì‘ë‹µ í‘œì‹œ
                    message_placeholder.markdown(response['content'])
                    
                    # ëª¨ë¸ ì •ë³´ í‘œì‹œ
                    col1, col2 = st.columns(2)
                    with col1:
                        st.caption(f"**ëª¨ë¸**: {response['model']}")
                    with col2:
                        st.caption(f"**í† í° ì‚¬ìš©ëŸ‰**: {response['tokens']}")
                    
                    # ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": response['content'],
                        "model": response['model'],
                        "intent": intent_analysis['primary_intent']
                    })
                    
                    # ëŒ€í™” ê¸°ë¡ ì €ì¥
                    st.session_state.conversation_history.append({
                        "timestamp": datetime.now().isoformat(),
                        "user_input": prompt,
                        "ai_response": response['content'],
                        "model_used": response['model'],
                        "intent": intent_analysis['primary_intent'],
                        "tokens_used": response['tokens']
                    })
                    
                    # ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
                    if response['model'] not in st.session_state.model_usage:
                        st.session_state.model_usage[response['model']] = 0
                    st.session_state.model_usage[response['model']] += 1
                    
                else:
                    st.error(f"âŒ ì˜¤ë¥˜: {response.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

    # ì‚¬ìš© í†µê³„ í‘œì‹œ
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š ì‚¬ìš© í†µê³„")
    st.sidebar.markdown(f"**ì´ ëŒ€í™”**: {len(st.session_state.conversation_history)}")
    
    if st.session_state.model_usage:
        st.sidebar.markdown("**ëª¨ë¸ ì‚¬ìš©ëŸ‰**:")
        for model, count in st.session_state.model_usage.items():
            st.sidebar.markdown(f"- {model}: {count}íšŒ")

    # ë³µì¡í•œ ì¶”ë¡  ì˜ˆì‹œ
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ¯ ë³µì¡í•œ ì¶”ë¡  ì˜ˆì‹œ")
    st.sidebar.markdown("""
    - "ì´ ë…¼ë¦¬ì˜ íƒ€ë‹¹ì„±ì„ ë¶„ì„í•´ì¤˜"
    - "ë‹¤ìŒ ì£¼ì¥ì˜ ì „ì œì™€ ê²°ë¡ ì„ ë¹„íŒì ìœ¼ë¡œ í‰ê°€í•´ì¤˜" 
    - "ì´ ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ì¶”ë¡ í•´ì¤˜"
    - "Aì™€ B ì ‘ê·¼ë²•ì˜ ì¥ë‹¨ì ì„ ê¹Šì´ ìˆê²Œ ë¹„êµë¶„ì„í•´ì¤˜"
    """)

if __name__ == "__main__":
    main()
