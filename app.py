import streamlit as st
import google.generativeai as genai
import requests
import sqlite3
import hashlib
import time
import logging
from datetime import datetime
from typing import Dict, List, Optional
import json
import os

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ§  í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° LLM ì‹œìŠ¤í…œ",
    page_icon="ğŸ”®",
    layout="wide",
    initial_sidebar_state="expanded"
)

class AdvancedAISystem:
    def __init__(self):
        self.setup_api_keys()
        self.setup_database()
        self.initialize_session_state()
        logger.info("ê³ ê¸‰ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_api_keys(self):
        """API í‚¤ ì„¤ì • - Streamlit Cloud Secrets ì‚¬ìš©"""
        try:
            # Google Gemini
            if 'GEMINI_API_KEY' in st.secrets:
                genai.configure(api_key=st.secrets['GEMINI_API_KEY'])
                self.gemini_available = True
                logger.info("Gemini API ì„¤ì • ì™„ë£Œ")
            else:
                self.gemini_available = False
                logger.warning("Gemini API í‚¤ ì—†ìŒ")
            
            # OpenRouter (Claude ë“±)
            self.openrouter_key = st.secrets.get('OPENROUTER_API_KEY', '')
            self.openrouter_available = bool(self.openrouter_key)
            if self.openrouter_available:
                logger.info("OpenRouter API ì„¤ì • ì™„ë£Œ")
            
            # DeepSeek
            self.deepseek_key = st.secrets.get('DEEPSEEK_API_KEY', '')
            self.deepseek_available = bool(self.deepseek_key)
            if self.deepseek_available:
                logger.info("DeepSeek API ì„¤ì • ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
            st.error("API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def setup_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
        try:
            self.conn = sqlite3.connect('ai_system.db', check_same_thread=False)
            cursor = self.conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    user_message TEXT,
                    bot_response TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    model_used TEXT,
                    intent_detected TEXT,
                    processing_time REAL,
                    tokens_used INTEGER
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS model_performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    model_name TEXT,
                    intent_type TEXT,
                    success_count INTEGER DEFAULT 0,
                    total_count INTEGER DEFAULT 0,
                    avg_response_time REAL,
                    last_used DATETIME
                )
            ''')
            
            self.conn.commit()
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        if 'user_id' not in st.session_state:
            st.session_state.user_id = hashlib.md5(
                str(datetime.now().timestamp()).encode()
            ).hexdigest()
        
        if 'model_stats' not in st.session_state:
            st.session_state.model_stats = {}
        
        if 'intent_stats' not in st.session_state:
            st.session_state.intent_stats = {}

    def advanced_intent_analysis(self, user_input: str) -> Dict:
        """ê³ ê¸‰ ì˜ë„ ë¶„ì„ ì‹œìŠ¤í…œ - ê°•í™”ëœ ë²„ì „"""
        intent_keywords = {
            'complex_reasoning': [
                'ë…¼ë¦¬', 'ì¶”ë¡ ', 'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'íŒë‹¨', 'ê²°ë¡ ', 'ê°€ì •',
                'ì „ì œ', 'ë…¼ì¦', 'íƒ€ë‹¹ì„±', 'ë¹„íŒì ', 'ì‚¬ê³ ', 'ì´ìœ ', 'ê·¼ê±°',
                'ë³µì¡í•œ', 'ë‚œì´ë„', 'ì‹¬ì¸µ', 'ë‹¤ë‹¨ê³„', 'ì¢…í•©', 'í†µí•©', 'ì² í•™',
                'ëª¨ìˆœ', 'ë…¼ìŸ', 'ì£¼ì¥', 'ë°˜ë°•', 'ì…ì¦', 'ì²´ê³„ì '
            ],
            'technical': [
                'ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°', 'ì•Œê³ ë¦¬ì¦˜', 'ê°œë°œ', 'ì„¤ê³„', 'íŒŒì´ì¬', 'ìë°”', 
                'í•¨ìˆ˜', 'í´ë˜ìŠ¤', 'ë””ë²„ê¹…', 'ì»´íŒŒì¼', 'ì¸í„°í˜ì´ìŠ¤', 'ë°ì´í„°ë² ì´ìŠ¤',
                'API', 'JSON', 'XML', 'HTML', 'CSS', 'JavaScript', 'ë¦¬íŒ©í† ë§'
            ],
            'creative': [
                'ì‘ì„±', 'ìƒì„±', 'ë§Œë“¤', 'ê¸€ì“°ê¸°', 'ì‹œ', 'ì´ì•¼ê¸°', 'ì°½ì˜', 'ì†Œì„¤',
                'ì•„ì´ë””ì–´', 'ê¸°íš', 'ì½˜í…ì¸ ', 'ìŠ¤í† ë¦¬', 'í”Œë¡¯', 'ìºë¦­í„°', 'ì‹œë‚˜ë¦¬ì˜¤'
            ],
            'mathematical': [
                'ê³„ì‚°', 'ìˆ˜í•™', 'ê³µì‹', 'ë°©ì •ì‹', 'í†µê³„', 'í™•ë¥ ', 'ë¯¸ë¶„', 'ì ë¶„',
                'ìˆ˜ì¹˜', 'ì‚¼ê°í•¨ìˆ˜', 'ê¸°í•˜', 'ëŒ€ìˆ˜', 'ìˆ˜ì—´', 'í–‰ë ¬', 'ë²¡í„°'
            ],
            'research': [
                'ì—°êµ¬', 'ë…¼ë¬¸', 'ì°¸ê³ ë¬¸í—Œ', 'í•™ìˆ ', 'ì´ë¡ ', 'ì‹¤í—˜', 'ë°ì´í„°', 'ì¡°ì‚¬',
                'ë¶„ì„', 'ê²°ê³¼', 'ê°€ì„¤', 'ë°©ë²•ë¡ ', 'ì°¸ê³ ', 'ì¸ìš©', 'ë¬¸í—Œ'
            ],
            'factual': [
                'ë­ì•¼', 'ë¬´ì—‡', 'ì•Œë ¤ì¤˜', 'ì •ë³´', 'ì‚¬ì‹¤', 'ì •ì˜', 'ì„¤ëª…', 'ê°œë…',
                'ì—­ì‚¬', 'ë°±ê³¼ì‚¬ì „', 'ì‚¬ì „', 'ì˜ë¯¸'
            ],
            'analytical': [
                'ë¶„ì„', 'ë¹„êµ', 'ì¥ë‹¨ì ', 'ì™œ', 'ì–´ë–»ê²Œ', 'ì›ì¸', 'ê²°ê³¼', 'í•´ì„',
                'í‰ê°€', 'ì˜ê²¬', 'ê´€ì ', 'ì‹œì‚¬ì ', 'í•¨ì˜'
            ],
            'casual': [
                'ì•ˆë…•', 'í•˜ì´', 'ì˜ì§€ë‚´', 'ê³ ë§ˆì›Œ', 'ë°˜ê°€ì›Œ', 'í—¤ì´', 'êµ¿', 'ì¢‹ì•„',
                'ã…‹ã…‹', 'ã…ã…', 'ã… ã… ', 'ã…œã…œ', 'í•˜ë£¨', 'ê¸°ë¶„'
            ]
        }
        
        # ì˜ë„ ì ìˆ˜ ê³„ì‚°
        intent_scores = {}
        user_lower = user_input.lower()
        
        for intent, keywords in intent_keywords.items():
            score = sum(10 for keyword in keywords if keyword in user_lower)
            if score > 0:
                intent_scores[intent] = score
        
        # ê³ ê¸‰ ë³µì¡ë„ ë¶„ì„
        word_count = len(user_input.split())
        char_count = len(user_input)
        
        # ë³µì¡ë„ ì§€í‘œ
        has_complex_words = any(word in user_lower for word in [
            'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'ë…¼ë¦¬', 'ì¶”ë¡ ', 'ì „ì œ', 'ê²°ë¡ ', 'ì²´ê³„ì ', 'ë‹¤ë‹¨ê³„'
        ])
        has_technical_terms = any(word in user_lower for word in [
            'ì•Œê³ ë¦¬ì¦˜', 'í•¨ìˆ˜', 'í´ë˜ìŠ¤', 'ë°ì´í„°ë² ì´ìŠ¤', 'API'
        ])
        has_research_terms = any(word in user_lower for word in [
            'ì—°êµ¬', 'ë…¼ë¬¸', 'ì´ë¡ ', 'ê°€ì„¤', 'ë°©ë²•ë¡ '
        ])
        
        # ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°
        complexity_score = 0
        complexity_score += min(word_count // 3, 20)  # ë‹¨ì–´ ìˆ˜ ê¸°ì—¬
        complexity_score += 15 if has_complex_words else 0
        complexity_score += 10 if has_technical_terms else 0
        complexity_score += 10 if has_research_terms else 0
        
        # ë³µì¡ë„ ë ˆë²¨ ê²°ì •
        if complexity_score >= 40:
            complexity = 'very_high'
        elif complexity_score >= 25:
            complexity = 'high'
        elif complexity_score >= 15:
            complexity = 'medium'
        else:
            complexity = 'low'
        
        # ì£¼ìš” ì˜ë„ ì„ íƒ (ë³µì¡í•œ ì¶”ë¡  ìš°ì„ )
        primary_intent = 'general'
        if intent_scores:
            if 'complex_reasoning' in intent_scores and intent_scores['complex_reasoning'] >= 15:
                primary_intent = 'complex_reasoning'
            else:
                primary_intent = max(intent_scores.items(), key=lambda x: x[1])[0]
        
        return {
            'primary_intent': primary_intent,
            'all_intents': list(intent_scores.keys()),
            'intent_scores': intent_scores,
            'complexity': complexity,
            'complexity_score': complexity_score,
            'word_count': word_count,
            'char_count': char_count,
            'is_complex': complexity in ['high', 'very_high']
        }

    def select_optimal_model(self, intent_analysis: Dict) -> Dict:
        """ìµœì ì˜ AI ëª¨ë¸ ì„ íƒ - ê°œì„ ëœ ë²„ì „"""
        
        # ê¸°ë³¸ ëª¨ë¸ ë§¤í•‘
        intent_model_mapping = {
            'complex_reasoning': {
                'primary': 'claude',
                'reason': 'ğŸ§  ë³µì¡í•œ ë…¼ë¦¬/ì¶”ë¡ ì—ëŠ” Claude 3.5 Sonnetì´ ê°€ì¥ ìš°ìˆ˜',
                'backup': 'gemini_advanced',
                'specialization': 'ë…¼ë¦¬ì  ì¶”ë¡ , ì²´ê³„ì  ë¶„ì„'
            },
            'technical': {
                'primary': 'deepseek',
                'reason': 'ğŸ’» ì½”ë“œ ë° ê¸°ìˆ ì  ë¬¸ì œ í•´ê²°ì—ëŠ” DeepSeek V3ê°€ ìµœì í™”',
                'backup': 'gemini',
                'specialization': 'í”„ë¡œê·¸ë˜ë°, ì•Œê³ ë¦¬ì¦˜, ê°œë°œ'
            },
            'mathematical': {
                'primary': 'gemini_advanced',
                'reason': 'ğŸ§® ìˆ˜í•™ì /ë…¼ë¦¬ì  ì—°ì‚°ì—ëŠ” Gemini 1.5 Proê°€ ê°•ë ¥',
                'backup': 'deepseek',
                'specialization': 'ìˆ˜í•™, ê³„ì‚°, ê³µì‹'
            },
            'research': {
                'primary': 'gemini_advanced',
                'reason': 'ğŸ“š ë°©ëŒ€í•œ í…ìŠ¤íŠ¸/ì—°êµ¬ ë¶„ì„ì—ëŠ” Geminiì˜ ê¸´ ì»¨í…ìŠ¤íŠ¸ ì°½ì´ ìœ ë¦¬',
                'backup': 'claude',
                'specialization': 'ì—°êµ¬, ë…¼ë¬¸, í•™ìˆ  ë¶„ì„'
            },
            'analytical': {
                'primary': 'claude',
                'reason': 'ğŸ” ë¶„ì„ì  ì‚¬ê³ ì™€ ë‹¤ê°ë„ ì ‘ê·¼ì—ëŠ” Claudeê°€ ë›°ì–´ë‚¨',
                'backup': 'gemini_advanced',
                'specialization': 'ë¶„ì„, ë¹„êµ, í‰ê°€'
            },
            'creative': {
                'primary': 'claude',
                'reason': 'ğŸ¨ ìì—°ìŠ¤ëŸ½ê³  ì°½ì˜ì ì¸ ì‘ë¬¸ì€ Claudeê°€ ë›°ì–´ë‚¨',
                'backup': 'gemini',
                'specialization': 'ì°½ì˜ì„±, ì•„ì´ë””ì–´, ê¸€ì“°ê¸°'
            },
            'factual': {
                'primary': 'gemini',
                'reason': 'ğŸ“– ì‚¬ì‹¤ì  ì •ë³´ ê²€ìƒ‰ì—ëŠ” Geminiì˜ ì •í™•ë„ê°€ ë†’ìŒ',
                'backup': 'claude',
                'specialization': 'ì‚¬ì‹¤, ì •ë³´, ì •ì˜'
            },
            'general': {
                'primary': 'gemini',
                'reason': 'âš¡ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì—ëŠ” ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ Gemini Flash ì‚¬ìš©',
                'backup': 'claude',
                'specialization': 'ì¼ë°˜ ëŒ€í™”, ê¸°ë³¸ ì§ˆë¬¸'
            }
        }
        
        # ë³µì¡ë„ê°€ ë§¤ìš° ë†’ìœ¼ë©´ ê³ ì„±ëŠ¥ ëª¨ë¸ ìš°ì„ 
        primary_intent = intent_analysis['primary_intent']
        if intent_analysis['complexity'] == 'very_high':
            if primary_intent in ['technical', 'mathematical']:
                # ê¸°ìˆ /ìˆ˜í•™ ë³µì¡ ë¬¸ì œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                pass
            else:
                # ê·¸ ì™¸ ë³µì¡í•œ ë¬¸ì œëŠ” ë³µì¡í•œ ì¶”ë¡ ìœ¼ë¡œ ì·¨ê¸‰
                primary_intent = 'complex_reasoning'
        
        model_choice = intent_model_mapping.get(primary_intent, intent_model_mapping['general'])
        
        # ëª¨ë¸ ê°€ìš©ì„± ì²´í¬ ë° í´ë°± ë¡œì§
        selected_model = model_choice['primary']
        original_reason = model_choice['reason']
        
        # ê°€ìš©ì„± ì²´í¬ ë° ì¡°ì •
        if selected_model == 'claude' and not self.openrouter_available:
            selected_model = model_choice['backup']
            model_choice['reason'] = f"ğŸš« Claude ì‚¬ìš© ë¶ˆê°€ â†’ {original_reason} (ë°±ì—… ëª¨ë¸ ì‚¬ìš©)"
        
        if selected_model == 'deepseek' and not self.deepseek_available:
            selected_model = 'gemini' if self.gemini_available else 'claude' if self.openrouter_available else 'none'
            model_choice['reason'] = f"ğŸš« DeepSeek ì‚¬ìš© ë¶ˆê°€ â†’ {original_reason} (ë°±ì—… ëª¨ë¸ ì‚¬ìš©)"
        
        if 'gemini' in selected_model and not self.gemini_available:
            if selected_model == 'gemini_advanced':
                selected_model = 'claude' if self.openrouter_available else 'deepseek' if self.deepseek_available else 'none'
            else:
                selected_model = 'claude' if self.openrouter_available else 'deepseek' if self.deepseek_available else 'none'
            model_choice['reason'] = f"ğŸš« Gemini ì‚¬ìš© ë¶ˆê°€ â†’ {original_reason} (ë°±ì—… ëª¨ë¸ ì‚¬ìš©)"
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°
        if selected_model == 'none':
            model_choice['reason'] = "âŒ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        model_choice['primary'] = selected_model
        return model_choice

    def call_gemini_api(self, prompt: str, intent: str, is_advanced: bool = False) -> Dict:
        """Gemini API í˜¸ì¶œ - ì•ˆì •ì ì¸ ë²„ì „"""
        if not self.gemini_available:
            return {'success': False, 'error': 'Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        try:
            start_time = time.time()
            
            # ëª¨ë¸ ì„ íƒ
            if is_advanced:
                model_name = 'gemini-1.5-pro'
            else:
                model_name = 'gemini-1.5-flash'
            
            # ì˜ë„ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
            reasoning_prompts = {
                'complex_reasoning': """
                ë‹¹ì‹ ì€ ë…¼ë¦¬ì  ì¶”ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•´ì£¼ì„¸ìš”:

                ğŸ’­ **ì‚¬ê³  í”„ë ˆì„ì›Œí¬**
                1. í•µì‹¬ ë¬¸ì œ ì‹ë³„ ë° êµ¬ì¡°í™”
                2. ëª…ì‹œì /ì•”ë¬µì  ì „ì œ ë¶„ì„  
                3. ë‹¤ê°ë„ ë…¼ë¦¬ ì „ê°œ
                4. ê²°ë¡  ë„ì¶œ ë° ê²€ì¦
                5. í•¨ì˜ì™€ í•œê³„ ëª…ì‹œ

                ì§ˆë¬¸: {prompt}
                """,
                'technical': """
                ë‹¹ì‹ ì€ ìˆ˜ì„ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤:

                ğŸ”§ **ê°œë°œ ë°©ë²•ë¡ **
                1. ìš”êµ¬ì‚¬í•­ ëª…í™•í™”
                2. ì•„í‚¤í…ì²˜ ì„¤ê³„
                3. íš¨ìœ¨ì  êµ¬í˜„
                4. ì—ëŸ¬ ì²˜ë¦¬ ë° ìµœì í™”
                5. ì‚¬ìš©ë²• ì„¤ëª…

                ì§ˆë¬¸: {prompt}
                """,
                'mathematical': """
                ë‹¹ì‹ ì€ ìˆ˜í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤:

                ğŸ§® **ë¬¸ì œ í•´ê²° ì ‘ê·¼ë²•**
                1. ë¬¸ì œ ì¬ì •ì˜ ë° ë³€ìˆ˜ ì„¤ì •
                2. ê´€ë ¨ ì´ë¡ /ê³µì‹ ì ìš©
                3. ë‹¨ê³„ë³„ ê³„ì‚° ê³¼ì •
                4. ê²°ê³¼ ê²€ì¦
                5. ì¼ë°˜í™” ê°€ëŠ¥ì„± íƒêµ¬

                ì§ˆë¬¸: {prompt}
                """,
                'research': """
                ë‹¹ì‹ ì€ ì—°êµ¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤:

                ğŸ“Š **í•™ë¬¸ì  ë¶„ì„**
                1. ì—°êµ¬ ì§ˆë¬¸ ëª…í™•í™”
                2. ë°©ë²•ë¡  ì ì ˆì„± í‰ê°€
                3. ì¦ê±° ìˆ˜ì¤€ ë¶„ì„
                4. ê²°ë¡  ë„ì¶œ ë° í•¨ì˜
                5. í•œê³„ì ê³¼ í–¥í›„ ë°©í–¥

                ì§ˆë¬¸: {prompt}
                """
            }
            
            system_prompt = reasoning_prompts.get(
                intent, 
                "ëª…í™•í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”: {prompt}"
            ).format(prompt=prompt)
            
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(system_prompt)
            
            processing_time = time.time() - start_time
            
            return {
                'success': True,
                'content': response.text,
                'model': f"Google {model_name}",
                'processing_time': processing_time,
                'tokens': len(system_prompt + response.text) // 4
            }
            
        except Exception as e:
            logger.error(f"Gemini API ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': f'Gemini API ì˜¤ë¥˜: {str(e)}'}

    def call_openrouter_api(self, prompt: str, intent: str) -> Dict:
        """OpenRouter API í˜¸ì¶œ - Claude ë“±"""
        if not self.openrouter_available:
            return {'success': False, 'error': 'OpenRouter APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        try:
            start_time = time.time()
            
            # ì˜ë„ë³„ ìµœì  ëª¨ë¸ ì„ íƒ
            intent_models = {
                'complex_reasoning': 'anthropic/claude-3.5-sonnet',
                'research': 'anthropic/claude-3.5-sonnet', 
                'analytical': 'anthropic/claude-3.5-sonnet',
                'creative': 'anthropic/claude-3.5-sonnet',
                'technical': 'google/gemini-2.0-flash',
                'mathematical': 'google/gemini-2.0-flash',
                'general': 'google/gemini-2.0-flash'
            }
            
            selected_model = intent_models.get(intent, 'anthropic/claude-3.5-sonnet')
            
            # Claude íŠ¹í™” í”„ë¡¬í”„íŠ¸
            claude_prompts = {
                'complex_reasoning': """
                <thinking_framework>
                ë‹¹ì‹ ì€ ë³µì¡í•œ ë¬¸ì œ í•´ê²° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¬ì¸µì  ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
                
                1. ë¬¸ì œ êµ¬ì¡°í™”: í•µì‹¬ ì´ìŠˆì™€ í•˜ìœ„ ë¬¸ì œ ë¶„í•´
                2. ë‹¤ì¤‘ ê´€ì : ë‹¤ì–‘í•œ ë Œì¦ˆë¥¼ í†µí•œ ì ‘ê·¼
                3. ì—°ì—­ì  ì¶”ë¡ : ì¼ë°˜ ì›ë¦¬ì—ì„œ íŠ¹ìˆ˜ ê²°ë¡  ë„ì¶œ  
                4. ê·€ë‚©ì  ì¼ë°˜í™”: êµ¬ì²´ì  ì‚¬ë¡€ì—ì„œ íŒ¨í„´ ë°œê²¬
                5. ë¹„íŒì  ê²€í† : ê°€ì •ê³¼ ê²°ë¡ ì˜ íƒ€ë‹¹ì„± í‰ê°€
                </thinking_framework>

                ì§ˆë¬¸: {prompt}
                """,
                'research': """
                <research_methodology>
                ë‹¹ì‹ ì€ ì—°êµ¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ë¬¸ì  ì—„ë°€ì„±ì„ ìœ ì§€í•´ì£¼ì„¸ìš”:
                
                1. ë¬¸í—Œ ê²€í† : ê¸°ì¡´ ì—°êµ¬ì™€ì˜ ì—°ê³„ì„± ë¶„ì„
                2. ë°©ë²•ë¡  ê²€ì¦: ë¶„ì„ ì ‘ê·¼ë²•ì˜ ì ì ˆì„± í‰ê°€
                3. ì¦ê±° ìˆ˜ì¤€: ì£¼ì¥ì˜ ê·¼ê±° ê°•ë„ íŒë‹¨
                4. í•¨ì˜ ë„ì¶œ: ì—°êµ¬ ê²°ê³¼ì˜ ì‹¤ì œì  ì˜ë¯¸
                5. í•œê³„ ì¸ì‹: ë¶„ì„ì˜ ì œí•œì  ëª…ì‹œ
                </research_methodology>

                ì§ˆë¬¸: {prompt}
                """
            }
            
            if selected_model.startswith('anthropic/claude'):
                base_prompt = claude_prompts.get(intent, "ì‹¬ë„ ìˆê²Œ ë¶„ì„í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”: {prompt}")
                final_prompt = base_prompt.format(prompt=prompt)
            else:
                final_prompt = prompt
            
            data = {
                "model": selected_model,
                "messages": [{"role": "user", "content": final_prompt}],
                "max_tokens": 4000,
                "temperature": 0.3
            }
            
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.openrouter_key}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://streamlit.io",
                    "X-Title": "AI Orchestrator"
                },
                json=data,
                timeout=60
            )
            
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens = result.get('usage', {}).get('total_tokens', 0)
                
                model_name = "Claude 3.5 Sonnet" if "claude" in selected_model else "Gemini 2.0 Flash"
                
                return {
                    'success': True,
                    'content': content,
                    'model': model_name,
                    'processing_time': processing_time,
                    'tokens': tokens
                }
            else:
                return {
                    'success': False, 
                    'error': f'OpenRouter API ì˜¤ë¥˜: {response.status_code} - {response.text}'
                }
                
        except Exception as e:
            logger.error(f"OpenRouter ì—°ê²° ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': f'OpenRouter ì—°ê²° ì˜¤ë¥˜: {str(e)}'}

    def call_deepseek_api(self, prompt: str, intent: str) -> Dict:
        """DeepSeek API í˜¸ì¶œ"""
        if not self.deepseek_available:
            return {'success': False, 'error': 'DeepSeek APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        try:
            start_time = time.time()
            
            # DeepSeek íŠ¹í™” í”„ë¡¬í”„íŠ¸
            deepseek_prompts = {
                'technical': """
                [ì½”ë”© ì „ë¬¸ê°€ ëª¨ë“œ]
                ë‹¹ì‹ ì€ ìˆ˜ì„ ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ì›ì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
                
                1. íš¨ìœ¨ì ì´ê³  ì½ê¸° ì‰¬ìš´ ì½”ë“œ ì‘ì„±
                2. ì—ëŸ¬ ì²˜ë¦¬ì™€ ì˜ˆì™¸ ìƒí™© ê³ ë ¤
                3. ëª¨ë²” ì‚¬ë¡€ì™€ íŒ¨í„´ ì ìš©
                4. ìƒì„¸í•œ ì£¼ì„ê³¼ ì„¤ëª… ì œê³µ
                5. í™•ì¥ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± ê³ ë ¤
                
                ì§ˆë¬¸: {prompt}
                """,
                'mathematical': """
                [ìˆ˜í•™ ì „ë¬¸ê°€ ëª¨ë“œ] 
                ì²´ê³„ì ì¸ ë¬¸ì œ í•´ê²°:
                
                1. ë¬¸ì œ ì´í•´ ë° ë³€ìˆ˜ ì •ì˜
                2. ê´€ë ¨ ê³µì‹/ì•Œê³ ë¦¬ì¦˜ ì ìš©
                3. ë‹¨ê³„ë³„ ê³„ì‚° ê³¼ì •
                4. ê²°ê³¼ ê²€ì¦ ë° ì„¤ëª…
                5. ì‹¤ìš©ì  ì‘ìš© ì œì‹œ
                
                ì§ˆë¬¸: {prompt}
                """
            }
            
            system_prompt = deepseek_prompts.get(
                intent, 
                "ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”: {prompt}"
            ).format(prompt=prompt)
            
            data = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": system_prompt}],
                "max_tokens": 4000,
                "temperature": 0.1
            }
            
            response = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {self.deepseek_key}"},
                json=data,
                timeout=60
            )
            
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens = result.get('usage', {}).get('total_tokens', 0)
                
                return {
                    'success': True,
                    'content': content,
                    'model': "DeepSeek V3",
                    'processing_time': processing_time,
                    'tokens': tokens
                }
            else:
                return {
                    'success': False,
                    'error': f'DeepSeek API ì˜¤ë¥˜: {response.status_code}'
                }
                
        except Exception as e:
            logger.error(f"DeepSeek API ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': f'DeepSeek API ì˜¤ë¥˜: {str(e)}'}

    def intelligent_model_orchestration(self, user_input: str) -> Dict:
        """ì§€ëŠ¥í˜• ëª¨ë¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""
        start_time = time.time()
        
        # 1. ê³ ê¸‰ ì˜ë„ ë¶„ì„
        intent_analysis = self.advanced_intent_analysis(user_input)
        
        # 2. ìµœì  ëª¨ë¸ ì„ íƒ
        model_choice = self.select_optimal_model(intent_analysis)
        
        # 3. ì„ íƒëœ ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
        selected_model = model_choice['primary']
        responses = {}
        
        if selected_model == 'claude':
            response = self.call_openrouter_api(user_input, intent_analysis['primary_intent'])
            if response['success']:
                responses['claude'] = response
        elif selected_model == 'deepseek':
            response = self.call_deepseek_api(user_input, intent_analysis['primary_intent'])
            if response['success']:
                responses['deepseek'] = response
        elif selected_model == 'gemini_advanced':
            response = self.call_gemini_api(user_input, intent_analysis['primary_intent'], True)
            if response['success']:
                responses['gemini_advanced'] = response
        elif selected_model == 'gemini':
            response = self.call_gemini_api(user_input, intent_analysis['primary_intent'], False)
            if response['success']:
                responses['gemini'] = response
        
        # 4. ê¸°ë³¸ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ë°±ì—… ëª¨ë¸ ì‹œë„
        if not responses:
            backup_model = model_choice.get('backup')
            if backup_model == 'claude' and self.openrouter_available:
                response = self.call_openrouter_api(user_input, intent_analysis['primary_intent'])
                if response['success']:
                    responses['claude'] = response
                    selected_model = 'claude'
                    model_choice['reason'] += " (ì£¼ ëª¨ë¸ ì‹¤íŒ¨ â†’ ë°±ì—… ì‚¬ìš©)"
            elif backup_model == 'gemini' and self.gemini_available:
                response = self.call_gemini_api(user_input, intent_analysis['primary_intent'], False)
                if response['success']:
                    responses['gemini'] = response
                    selected_model = 'gemini'
                    model_choice['reason'] += " (ì£¼ ëª¨ë¸ ì‹¤íŒ¨ â†’ ë°±ì—… ì‚¬ìš©)"
            elif backup_model == 'deepseek' and self.deepseek_available:
                response = self.call_deepseek_api(user_input, intent_analysis['primary_intent'])
                if response['success']:
                    responses['deepseek'] = response
                    selected_model = 'deepseek'
                    model_choice['reason'] += " (ì£¼ ëª¨ë¸ ì‹¤íŒ¨ â†’ ë°±ì—… ì‚¬ìš©)"
        
        # 5. ìµœì¢… ì‘ë‹µ ì„ íƒ
        final_response = self.get_final_response(responses)
        total_processing_time = time.time() - start_time
        
        result = {
            'final_response': final_response,
            'selected_model': selected_model,
            'model_reason': model_choice['reason'],
            'model_specialization': model_choice.get('specialization', 'ì¼ë°˜'),
            'intent_analysis': intent_analysis,
            'processing_time': total_processing_time,
            'success': bool(responses)
        }
        
        # ì„±ê³µí•œ ì‘ë‹µì´ ìˆìœ¼ë©´ ìƒì„¸ ì •ë³´ ì¶”ê°€
        if responses:
            first_response = next(iter(responses.values()))
            result.update({
                'content': first_response['content'],
                'model_name': first_response['model'],
                'response_time': first_response['processing_time'],
                'tokens_used': first_response['tokens']
            })
        
        return result

    def get_final_response(self, responses: Dict) -> str:
        """ìµœì¢… ì‘ë‹µ ì„ íƒ"""
        if responses:
            # ì²« ë²ˆì§¸ ì„±ê³µí•œ ì‘ë‹µ ì‚¬ìš©
            for response in responses.values():
                if response['success']:
                    return response['content']
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ
        return """
        ğŸ¤– **AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ìœ¼ë¡œ ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤**
        
        ê°€ëŠ¥í•œ ì›ì¸:
        - API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë§Œë£Œë¨
        - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ
        - ì„œë¹„ìŠ¤ ì¼ì‹œì  ì¤‘ë‹¨
        
        âœ… **í•´ê²° ë°©ë²•**:
        1. Streamlit Cloud Secretsì—ì„œ API í‚¤ í™•ì¸
        2. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„
        3. ì§ˆë¬¸ì„ ë” ê°„ë‹¨í•˜ê²Œ ì¬êµ¬ì„±
        """

    def save_conversation(self, user_input: str, result: Dict):
        """ëŒ€í™” ì €ì¥"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT INTO conversations 
                (session_id, user_message, bot_response, model_used, intent_detected, processing_time, tokens_used)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                st.session_state.user_id,
                user_input,
                result.get('content', ''),
                result.get('model_name', ''),
                result['intent_analysis']['primary_intent'],
                result['processing_time'],
                result.get('tokens_used', 0)
            ))
            
            self.conn.commit()
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ì €ì¥ ì˜¤ë¥˜: {e}")

    def display_advanced_sidebar(self):
        """ê³ ê¸‰ ì‚¬ì´ë“œë°” í‘œì‹œ"""
        with st.sidebar:
            st.title("ğŸ¯ AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°")
            
            # ì‹œìŠ¤í…œ ìƒíƒœ
            st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
            col1, col2, col3 = st.columns(3)
            col1.metric("Gemini", "âœ…" if self.gemini_available else "âŒ")
            col2.metric("Claude", "âœ…" if self.openrouter_available else "âŒ")
            col3.metric("DeepSeek", "âœ…" if self.deepseek_available else "âŒ")
            
            st.markdown("---")
            
            # ëª¨ë¸ íŠ¹ì„± ì•ˆë‚´
            st.subheader("ğŸ† ëª¨ë¸ íŠ¹ê¸°")
            st.markdown("""
            **Claude 3.5 Sonnet**
            - ë…¼ë¦¬ì  ì¶”ë¡ , ë³µì¡í•œ ë¶„ì„
            - ì°½ì˜ì  ì‘ë¬¸, ë‰˜ì•™ìŠ¤ ì´í•´
            
            **Gemini 1.5 Pro/Flash**  
            - ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬
            - ë©€í‹°ëª¨ë‹¬, ë¹ ë¥¸ ì‘ë‹µ
            - ìˆ˜í•™ì  ë¬¸ì œ í•´ê²°
            
            **DeepSeek V3**
            - ì½”ë”©, ì•Œê³ ë¦¬ì¦˜ ìµœì í™”
            - ìˆ˜í•™ì  ê³„ì‚°
            - ê°€ì„±ë¹„ ìš°ìˆ˜
            """)
            
            st.markdown("---")
            
            # ì‚¬ìš© íŒ
            st.subheader("ğŸ’¡ ì‚¬ìš© íŒ")
            st.markdown("""
            - **ë³µì¡í•œ ì¶”ë¡ **: Claude ì¶”ì²œ
            - **ì½”ë”© ë¬¸ì œ**: DeepSeek ì¶”ì²œ  
            - **ì—°êµ¬ ë¶„ì„**: Gemini Pro ì¶”ì²œ
            - **ë¹ ë¥¸ ì‘ë‹µ**: Gemini Flash ì¶”ì²œ
            """)
            
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°", use_container_width=True):
                st.session_state.messages = []
                st.rerun()

    def display_chat_interface(self):
        """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ"""
        st.title("ğŸ§  í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° LLM ì‹œìŠ¤í…œ")
        st.markdown("**ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ Claude, Gemini, DeepSeek ì¤‘ ìµœì ì˜ ëª¨ë¸ì„ ìë™ ì„ íƒí•©ë‹ˆë‹¤**")
        
        # ì±„íŒ… ê¸°ë¡
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # ë©”íƒ€ì •ë³´ í‘œì‹œ
                if message["role"] == "assistant" and "metadata" in message:
                    with st.expander("ğŸ” AI ë¶„ì„ ì •ë³´"):
                        metadata = message['metadata']
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**ëª¨ë¸**: {metadata['model_name']}")
                            st.write(f"**ì˜ë„**: {metadata['intent_analysis']['primary_intent']}")
                        with col2:
                            st.write(f"**ë³µì¡ë„**: {metadata['intent_analysis']['complexity']}")
                            st.write(f"**ì²˜ë¦¬ì‹œê°„**: {metadata['response_time']:.2f}s")
                        
                        st.info(f"**ì„ íƒ ì´ìœ **: {metadata['model_reason']}")
                        
                        # ì˜ë„ ì ìˆ˜ ì‹œê°í™”
                        if 'intent_scores' in metadata['intent_analysis']:
                            st.write("**ì˜ë„ ë¶„ì„**:")
                            for intent, score in metadata['intent_analysis']['intent_scores'].items():
                                progress = min(score / 100, 1.0)
                                st.progress(progress, text=f"{intent} ({score}ì )")
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ğŸ§  ì§ˆë¬¸ ë¶„ì„ ë° ìµœì  ëª¨ë¸ ì„ íƒ ì¤‘..."):
                    result = self.intelligent_model_orchestration(prompt)
                
                if result['success']:
                    st.markdown(result['content'])
                    
                    # ì‹¤ì‹œê°„ ë¶„ì„ ì •ë³´
                    with st.expander("ğŸ¯ ì‹¤ì‹œê°„ ë¼ìš°íŒ… ì •ë³´", expanded=True):
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("ì„ íƒ ëª¨ë¸", result['model_name'])
                        with col2:
                            st.metric("ê°ì§€ ì˜ë„", result['intent_analysis']['primary_intent'])
                        with col3:
                            st.metric("ë³µì¡ë„", result['intent_analysis']['complexity'])
                        with col4:
                            st.metric("í† í°", f"{result['tokens_used']}")
                        
                        st.info(f"**ì„ íƒ ì´ìœ **: {result['model_reason']}")
                        st.success(f"**ì „ë¬¸ ë¶„ì•¼**: {result['model_specialization']}")
                        
                        # ì²˜ë¦¬ ì‹œê°„
                        st.write(f"**ì´ ì²˜ë¦¬ ì‹œê°„**: {result['processing_time']:.2f}ì´ˆ")
                        
                else:
                    st.error("âŒ AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    st.info(result['final_response'])
            
            # ì„¸ì…˜ì— ë©”ì‹œì§€ ì €ì¥
            if result['success']:
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": result['content'],
                    "metadata": {
                        'model_name': result['model_name'],
                        'model_reason': result['model_reason'],
                        'intent_analysis': result['intent_analysis'],
                        'response_time': result.get('response_time', 0),
                        'tokens_used': result.get('tokens_used', 0)
                    }
                })
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                self.save_conversation(prompt, result)
            
            st.rerun()

def main():
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ai_system = AdvancedAISystem()
    
    # ì‚¬ì´ë“œë°” í‘œì‹œ
    ai_system.display_advanced_sidebar()
    
    # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    ai_system.display_chat_interface()
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: gray;'>"
        "ğŸ§  í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° LLM ì‹œìŠ¤í…œ â€¢ ì§€ëŠ¥í˜• ëª¨ë¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ â€¢ ì‹¤ì‹œê°„ ì˜ë„ ë¶„ì„"
        "</div>", 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()