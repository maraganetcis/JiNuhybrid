import streamlit as st
import asyncio
import google.generativeai as genai
import requests
from typing import Dict, List
import json
import time
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="JiNu hybrid AI",
    page_icon="âŒ˜",
    layout="wide"
)

class StreamlitAISystem:
    def __init__(self):
        self.setup_api_keys()
        self.initialize_session_state()
    
    def setup_api_keys(self):
        """Streamlit secretsì—ì„œ API í‚¤ ì„¤ì •"""
        try:
            # Google Gemini
            if 'GOOGLE_API_KEY' in st.secrets:
                genai.configure(api_key=st.secrets['GOOGLE_API_KEY'])
                self.gemini_available = True
            else:
                self.gemini_available = False
            
            # OpenRouter
            self.openrouter_key = st.secrets.get('OPENROUTER_API_KEY', '')
            self.openrouter_available = bool(self.openrouter_key)
            
            # DeepSeek
            self.deepseek_key = st.secrets.get('DEEPSEEK_API_KEY', '')
            self.deepseek_available = bool(self.deepseek_key)
            
        except Exception as e:
            st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        if 'usage_stats' not in st.session_state:
            st.session_state.usage_stats = {
                'total_queries': 0,
                'total_tokens': 0,
                'model_usage': {},
                'cost_estimate': 0.0
            }
    
    def advanced_intent_analysis(self, user_input: str) -> Dict:
        """ê³ ê¸‰ ì˜ë„ ë¶„ì„ ì‹œìŠ¤í…œ"""
        intent_keywords = {
            'complex_reasoning': [
                'ë…¼ë¦¬', 'ì¶”ë¡ ', 'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'íŒë‹¨', 'ê²°ë¡ ', 'ê°€ì •',
                'ì „ì œ', 'ë…¼ì¦', 'íƒ€ë‹¹ì„±', 'ë¹„íŒì ', 'ì‚¬ê³ ', 'ì´ìœ ', 'ê·¼ê±°',
                'ë³µì¡í•œ', 'ë‚œì´ë„', 'ì‹¬ì¸µ', 'ë‹¤ë‹¨ê³„', 'ì¢…í•©', 'í†µí•©'
            ],
            'technical': ['ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°', 'ì•Œê³ ë¦¬ì¦˜', 'ê°œë°œ', 'ì„¤ê³„', 'íŒŒì´ì¬', 'ìë°”'],
            'creative': ['ì‘ì„±', 'ìƒì„±', 'ë§Œë“¤', 'ê¸€ì“°ê¸°', 'ì‹œ', 'ì´ì•¼ê¸°', 'ì°½ì˜'],
            'mathematical': ['ê³„ì‚°', 'ìˆ˜í•™', 'ê³µì‹', 'ë°©ì •ì‹', 'í†µê³„', 'í™•ë¥ ', 'ë¯¸ë¶„'],
            'research': ['ì—°êµ¬', 'ë…¼ë¬¸', 'ì°¸ê³ ë¬¸í—Œ', 'í•™ìˆ ', 'ì´ë¡ ', 'ì‹¤í—˜', 'ë°ì´í„°'],
            'factual': ['ë­ì•¼', 'ë¬´ì—‡', 'ì•Œë ¤ì¤˜', 'ì •ë³´', 'ì‚¬ì‹¤', 'ì •ì˜'],
            'casual': ['ì•ˆë…•', 'í•˜ì´', 'ì˜ì§€ë‚´', 'ê³ ë§ˆì›Œ', 'ë°˜ê°€ì›Œ']
        }
        
        # ì˜ë„ ì ìˆ˜ ê³„ì‚°
        intent_scores = {}
        user_lower = user_input.lower()
        
        for intent, keywords in intent_keywords.items():
            score = sum(10 for keyword in keywords if keyword in user_lower)
            if score > 0:
                intent_scores[intent] = score
        
        # ë³µì¡ë„ ë¶„ì„
        word_count = len(user_input.split())
        has_complex_indicators = any(word in user_lower for word in [
            'ë¶„ì„', 'ë¹„êµ', 'í‰ê°€', 'ë…¼ë¦¬', 'ì¶”ë¡ ', 'ì „ì œ', 'ê²°ë¡ '
        ])
        
        if word_count > 20 or has_complex_indicators:
            complexity = 'very_high'
        elif word_count > 12:
            complexity = 'high'
        elif word_count > 6:
            complexity = 'medium'
        else:
            complexity = 'low'
        
        # ì£¼ìš” ì˜ë„ ì„ íƒ (ë³µì¡í•œ ì¶”ë¡  ìš°ì„ )
        if 'complex_reasoning' in intent_scores:
            primary_intent = 'complex_reasoning'
        else:
            primary_intent = max(intent_scores, key=intent_scores.get()) if intent_scores else 'general'
        
        return {
            'primary_intent': primary_intent,
            'all_intents': list(intent_scores.keys()),
            'intent_scores': intent_scores,
            'complexity': complexity,
            'word_count': word_count,
            'is_complex': complexity in ['high', 'very_high']
        }
    
    def select_optimal_model(self, intent_analysis: Dict) -> Dict:
        """ìµœì ì˜ AI ëª¨ë¸ ì„ íƒ"""
        intent_model_mapping = {
            'complex_reasoning': {
                'primary': 'claude',
                'reason': 'ğŸ§  ë³µì¡í•œ ì¶”ë¡ ì—ëŠ” Claude 3.5 Sonnetì´ ê°€ì¥ ìš°ìˆ˜í•¨',
                'backup': 'gemini_advanced'
            },
            'technical': {
                'primary': 'gemini',
                'reason': 'ğŸ”§ ê¸°ìˆ /ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” Geminiê°€ ìµœì í™”ë¨',
                'backup': 'claude'
            },
            'mathematical': {
                'primary': 'gemini_advanced',
                'reason': 'ğŸ§® ìˆ˜í•™ì  ì¶”ë¡ ì—ëŠ” Gemini Advancedê°€ ì •í™•ë„ ë†’ìŒ',
                'backup': 'claude'
            },
            'research': {
                'primary': 'claude', 
                'reason': 'ğŸ“Š ì—°êµ¬/í•™ìˆ  ë¶„ì„ì—ëŠ” Claudeì˜ ê¹Šì€ ì´í•´ë ¥ì´ ì í•©',
                'backup': 'gemini_advanced'
            },
            'creative': {
                'primary': 'claude',
                'reason': 'ğŸ¨ ì°½ì˜ì  ì‚¬ê³ ì—ëŠ” Claudeì˜ ìœ ì—°ì„±ì´ ì¢‹ìŒ',
                'backup': 'gemini'
            },
            'general': {
                'primary': 'gemini',
                'reason': 'âš¡ ì¼ë°˜ ì§ˆë¬¸ì—ëŠ” Geminiì˜ ë¹ ë¥¸ ì‘ë‹µì´ ì í•©',
                'backup': 'deepseek'
            }
        }
        
        # ë³µì¡ë„ê°€ ë§¤ìš° ë†’ìœ¼ë©´ ë³µì¡í•œ ì¶”ë¡  ëª¨ë¸ ê°•ì œ ì‚¬ìš©
        if intent_analysis['complexity'] == 'very_high':
            primary_intent = 'complex_reasoning'
        else:
            primary_intent = intent_analysis['primary_intent']
        
        model_choice = intent_model_mapping.get(primary_intent, intent_model_mapping['general'])
        return model_choice
    
    def call_ai_model(self, prompt: str, model_type: str, intent: str) -> Dict:
        """AI ëª¨ë¸ í˜¸ì¶œ"""
        reasoning_prompts = {
            'complex_reasoning': """
            ë‹¹ì‹ ì€ ë…¼ë¦¬ì  ì¶”ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì ‘ê·¼í•´ì£¼ì„¸ìš”:
            1. ë¬¸ì œì˜ í•µì‹¬ ìš”ì†Œ ë¶„ì„
            2. ê°€ì •ê³¼ ì „ì œ í™•ì¸  
            3. ë…¼ë¦¬ì  ì—°ê²°ê³ ë¦¬ ë„ì¶œ
            4. ê²°ë¡  ë„ì¶œ ë° ê²€ì¦
            
            ì§ˆë¬¸: {prompt}
            """,
            'mathematical': """
            ë‹¹ì‹ ì€ ìˆ˜í•™ì  ì‚¬ê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•´ì£¼ì„¸ìš”:
            1. ë¬¸ì œ ì´í•´ ë° ë³€ìˆ˜ ì •ì˜
            2. ê´€ë ¨ ê³µì‹/ì´ë¡  ì ìš©
            3. ë‹¨ê³„ë³„ ê³„ì‚°
            4. ê²°ê³¼ ê²€ì¦
            
            ì§ˆë¬¸: {prompt}
            """
        }
        
        specialized_prompt = reasoning_prompts.get(
            intent, 
            "ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”: {prompt}"
        ).format(prompt=prompt)
        
        try:
            if model_type in ['gemini', 'gemini_advanced'] and self.gemini_available:
                return self._call_gemini(specialized_prompt, model_type)
            elif model_type == 'claude' and self.openrouter_available:
                return self._call_claude(specialized_prompt)
            elif model_type == 'deepseek' and self.deepseek_available:
                return self._call_deepseek(specialized_prompt)
            else:
                return {'error': 'ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.'}
                
        except Exception as e:
            return {'error': f'ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}'}
    
    def _call_gemini(self, prompt: str, model_type: str) -> Dict:
        """Gemini ëª¨ë¸ í˜¸ì¶œ"""
        try:
            if model_type == 'gemini_advanced':
                model = genai.GenerativeModel('gemini-2.5-pro')
            else:
                model = genai.GenerativeModel('gemini-2.5-flash')
            
            response = model.generate_content(prompt)
            return {
                'success': True,
                'content': response.text,
                'model': 'Gemini ' + ('Advanced' if model_type == 'gemini_advanced' else 'Flash'),
                'tokens': len(prompt.split()) + len(response.text.split())
            }
        except Exception as e:
            return {'error': f'Gemini ì˜¤ë¥˜: {str(e)}'}
    
    def _call_claude(self, prompt: str) -> Dict:
        """Claude ëª¨ë¸ í˜¸ì¶œ"""
        try:
            data = {
                "model": "anthropic/claude-3.5-sonnet",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 2000,
                "temperature": 0.3
            }
            
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={"Authorization": f"Bearer {self.openrouter_key}"},
                json=data,
                timeout=45
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens = result.get('usage', {}).get('total_tokens', 0)
                
                return {
                    'success': True,
                    'content': content,
                    'model': 'Claude 3.5 Sonnet',
                    'tokens': tokens
                }
            else:
                return {'error': f'Claude API ì˜¤ë¥˜: {response.status_code}'}
                
        except Exception as e:
            return {'error': f'Claude í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}'}
    
    def _call_deepseek(self, prompt: str) -> Dict:
        """DeepSeek ëª¨ë¸ í˜¸ì¶œ"""
        try:
            data = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 2000,
                "temperature": 0.3
            }
            
            response = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {self.deepseek_key}"},
                json=data,
                timeout=45
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens = result.get('usage', {}).get('total_tokens', 0)
                
                return {
                    'success': True,
                    'content': content,
                    'model': 'DeepSeek V3',
                    'tokens': tokens
                }
            else:
                return {'error': f'DeepSeek API ì˜¤ë¥˜: {response.status_code}'}
                
        except Exception as e:
            return {'error': f'DeepSeek í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}'}
    
    def update_usage_stats(self, model: str, tokens: int):
        """ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸"""
        st.session_state.usage_stats['total_queries'] += 1
        st.session_state.usage_stats['total_tokens'] += tokens
        
        if model not in st.session_state.usage_stats['model_usage']:
            st.session_state.usage_stats['model_usage'][model] = 0
        st.session_state.usage_stats['model_usage'][model] += 1
        
        # ê°„ë‹¨í•œ ë¹„ìš© ì¶”ì • (í† í°ë‹¹ í‰ê·  $0.00001)
        st.session_state.usage_stats['cost_estimate'] += tokens * 0.00001

def main():
    st.title("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ AI ì–´ì‹œìŠ¤í„´íŠ¸")
    st.markdown("ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìµœì ì˜ AI ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ì„ íƒë©ë‹ˆë‹¤!")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ”§ ì„¤ì •")
        budget_mode = st.selectbox("ë¹„ìš© ëª¨ë“œ", ["ë¹„ìš© íš¨ìœ¨", "ì„±ëŠ¥ ìµœëŒ€"])
        
        st.header("ğŸ“Š ì‚¬ìš© í†µê³„")
        if 'usage_stats' in st.session_state:
            stats = st.session_state.usage_stats
            st.metric("ì´ ì§ˆë¬¸", stats['total_queries'])
            st.metric("ì´ í† í°", f"{stats['total_tokens']:,}")
            st.metric("ì˜ˆìƒ ë¹„ìš©", f"${stats['cost_estimate']:.4f}")
            
            if stats['model_usage']:
                st.subheader("ëª¨ë¸ ì‚¬ìš©ëŸ‰")
                for model, count in stats['model_usage'].items():
                    st.write(f"- {model}: {count}íšŒ")
    
    # AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ai_system = StreamlitAISystem()
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "model" in message:
                st.caption(f"ëª¨ë¸: {message['model']}")
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ì˜ë„ ë¶„ì„ ë° ëª¨ë¸ ì„ íƒ
        with st.spinner("ìµœì ì˜ AI ëª¨ë¸ì„ ì„ íƒ ì¤‘..."):
            intent_analysis = ai_system.advanced_intent_analysis(prompt)
            model_choice = ai_system.select_optimal_model(intent_analysis)
            
            # ë¹„ìš© íš¨ìœ¨ ëª¨ë“œì—ì„œëŠ” ì¼ë¶€ ëª¨ë¸ ë³€ê²½
            if budget_mode == "ë¹„ìš© íš¨ìœ¨" and model_choice['primary'] == 'claude':
                model_choice['primary'] = model_choice['backup']
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner(f"{model_choice['primary']} ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„± ì¤‘..."):
                response = ai_system.call_ai_model(
                    prompt, 
                    model_choice['primary'], 
                    intent_analysis['primary_intent']
                )
                
                if 'error' in response:
                    st.error(response['error'])
                else:
                    # ì‘ë‹µ í‘œì‹œ
                    st.markdown(response['content'])
                    st.caption(f"ëª¨ë¸: {response['model']} | í† í°: {response['tokens']}")
                    
                    # ì˜ë„ ë¶„ì„ ì •ë³´
                    with st.expander("ì˜ë„ ë¶„ì„ ê²°ê³¼ ë³´ê¸°"):
                        st.json(intent_analysis)
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    ai_system.update_usage_stats(response['model'], response['tokens'])
                    
                    # ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": response['content'],
                        "model": response['model']
                    })

if __name__ == "__main__":
    main()
